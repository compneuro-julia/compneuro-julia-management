本書の構成

第0部 イントロダクション

第1章では，Julia言語の使用法と用いる数学について簡単に説明する．

まとまりを重視するため，本書では発火率モデルおよびニューラルネットワークについて説明した後に，スパイキングモデルおよびスパイキングニューラルネットワークの説明を行う．

第1部 ニューラルネットワークとその学習

第2章では，まず神経細胞の簡単な生理学について説明する．発火率モデルを説明したのち，局所学習則によって訓練されるネットワークの説明を行う．第3章では，同じく局所学習則ではあるが，ネットワーク全体のエネルギーを下げることを目的としたエネルギーベースモデルと呼ばれる枠組みのネットワークについて説明をする．第4章では，誤差逆伝播法に基づいたニューラルネットワークを説明し，貢献度分配問題の生理学的な解決策について説明をする．第5章では，さらに再起型ニューラルネットワークを説明し，経時的貢献度分配問題について説明を行う．

第2部 スパイキングニューラルネットワークとその学習

第6章ではスパイキングニューラルネットワークの章では，初めにスパイキングニューロンのモデルについて説明を行う．次に，シナプスのダイナミクスについて説明を補いながらモデルを構築する．ランダムネットワークを構築した後に，ネットワークの学習則を説明する．

第3部 その他

- リザバーコンピューティングの章では，リザバーコンピューティングと呼ばれる枠組みのネットワークについて，発火率・スパイキングモデルの双方をまとめて紹介する．カオスの縁についても触れる．
- ベイズ推論の章では，神経回路網により，如何にして確率計算を行うかを説明する．
- 運動学習では，最適制御問題の解決策について説明する．
- 強化学習では，強化学習の基本的事項の説明と，大脳基底核との関連性について説明する．
- 最後の章は補足的な話題であり，ネットワーク・形態学・グリアについて説明を行う．


https://www.sciencedirect.com/science/article/pii/S0364021387800253

第1節：
---

まえがき

第1章：はじめに
- 本書の構成と目的
- Julia言語の使用法
- 基礎的数学

第2章：発火率モデルと局所学習則
- 神経細胞の生理
- 発火率モデルとHebb則　※
- 線形回帰※
- ロジスティック回帰とパーセプトロン※
- 主成分分析
- 独立成分分析
- 自己組織化マップと競合学習

第3章：エネルギーベースモデル
- Hopfield モデル
- Boltzmann マシン
- スパース符号化モデル
- 予測符号化モデル

第4章：ニューラルネットワークと貢献度分配問題
- 貢献度分配問題と誤差逆伝播法
- 非対称な逆向き投射による誤差伝播
- 予測符号化による活動と結合の共調整
- 摂動を用いた学習則

第5章：再帰型ニューラルネットワークと経時的貢献度分配問題
- 経時的誤差逆伝播法 (BPTT)
- 実時間リカレント学習 (RTRL)
- 適格度トレースによるRTRLの近似※

第6章：スパイキングニューロンとシナプスダイナミクス
- コンダクタンスベースモデル※
  - FitzHugh-Nagumoモデル
- 積分発火モデル※
- Izhikevich モデル※
- マルチコンパートメントモデル※
- Inter-spike interval モデル (点過程モデルの方がいいか※)
- シナプスの生理とCurrent/Conductance-based シナプス
- 指数関数型シナプスモデル
- 動力学シナプスモデル
- 短期的シナプス可塑性

第7章：スパイキングニューラルネットワークの学習則
- ランダム回路網の構成
- STDP則と競合学習
- 代理勾配法
- 適格性伝播法※

第9章：リザバーコンピューティング
- エコーステートネットワーク※
- FORCE法 (rate, spiking)※

第10章：神経回路によるベイズ推論
- ベイズ脳仮説と不確実性の表現
- ベイズ線形回帰
- 確率的集団符号化
- マルコフ連鎖モンテカルロ法
- 神経サンプリング

第11章：運動学習と最適制御
- 躍度最小モデル
- 終点誤差分散最小モデル
- 最適フィードバック制御モデル
- 無限時間最適制御モデル

第12章：強化学習
- 強化学習とマルコフ決定過程
- 状態価値の推定
- 価値ベース法
- 方策ベース法
- 分布型強化学習
- 内発的動機付け

第13章：神経・神経回路の発生・構造的モデル※
- 神経突起の成長モデル
- シナプス結合強度の不均一性