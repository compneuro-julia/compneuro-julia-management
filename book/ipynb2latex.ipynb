{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896a4096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import re\n",
    "import yaml\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from base64 import b64decode\n",
    "from io import BytesIO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fbc147",
   "metadata": {},
   "source": [
    "同じ文字が連続する場合は長い方から処理する．\n",
    "- ToDo: citationをどうにかする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c0f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '# aa\\n ## aaa\\n `this` is ``` **sample string** for *extracting substring*. {cite:p}`Echeveste2020-sh` <a>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed8dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown2latex(s):\n",
    "    # s: string\n",
    "    s = re.sub(r'\\####\\ (.+?)\\n', r'\\\\paragraph{\\1}\\n', s)  # subsubsection\n",
    "    s = re.sub(r'\\###\\ (.+?)\\n', r'\\\\subsubsection{\\1}\\n', s)  # subsubsection\n",
    "    s = re.sub(r'\\##\\ (.+?)\\n', r'\\\\subsection{\\1}\\n', s)  # subsection\n",
    "    s = re.sub(r'\\#\\ (.+?)\\n', r'\\\\section{\\1}\\n', s)      # section\n",
    "    \n",
    "    s = re.sub(r'\\*\\*(.+?)\\*\\*', r'\\\\textbf{\\1}', s)   # bold\n",
    "    #s = re.sub(r'\\*(.+?)\\*', r'\\\\textit{\\1}', s)       # italic\n",
    "    \n",
    "    s = s.replace(r\"```{note}\", \"\\\\footnote{\") # note to footnote\n",
    "    s = s.replace(r\"```\", \"}\")\n",
    "    s = re.sub(r'<(.+?)>', r'\\\\url{\\1}', s) # url\n",
    "\n",
    "    s = re.sub(r'{cite:p}`(.+?)`', r'\\\\cite{\\1}', s)     \n",
    "    s = re.sub(r'`(.+?)`', r'\\\\jl{\\1}', s) # inline code with \\newcommand{\\jl}{\\lstinline[language=julia]}\n",
    "\n",
    "    s = re.sub(r'<(.+?)>', r'\\\\url{\\1}', s) # url\n",
    "    s = s.replace(r\"（\", \" (\") \n",
    "    s = s.replace(r\"）\", \") \") \n",
    "    s = s.replace(r\"$$\", \"\") \n",
    "    #s = s.replace(r\"．\", \"．\\n\") \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "281faa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_itemized(text):\n",
    "    #splited_text = text.split('\\n')\n",
    "    #splited_text = all_remove(splited_text, \"\\n\")\n",
    "    splited_text = list(filter(None, text))\n",
    "    item_idx = [line[:2] == \"- \" for line in splited_text]\n",
    "    if np.sum(item_idx) > 0:\n",
    "        item_idx += [False]\n",
    "        item_startend = np.where(np.diff(np.array(item_idx)) == True)[0]\n",
    "        item_startend += np.arange(len(item_startend)) + 1\n",
    "\n",
    "        # replace - to \\item\n",
    "        for i in range(len(splited_text)):\n",
    "            if item_idx[i]:\n",
    "                splited_text[i] = splited_text[i].replace('- ', '\\item ', 1) \n",
    "\n",
    "        # add begin and end\n",
    "        for j in range(len(item_startend)):\n",
    "            if j % 2 == 0:\n",
    "                splited_text.insert(item_startend[j], \"\\\\begin{itemize}\")\n",
    "            else:\n",
    "                splited_text.insert(item_startend[j], \"\\\\end{itemize}\")\n",
    "    for i in range(len(splited_text)):\n",
    "        if splited_text[i][-1:] != \"\\n\":\n",
    "            splited_text[i] += \"\\n\"\n",
    "    return splited_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39487f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\section{aa}\\n \\\\subsection{aaa}\\n \\\\jl{this} is } \\\\textbf{sample string} for *extracting substring*. \\\\cite{Echeveste2020-sh} \\\\url{a}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown2latex(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f606d4",
   "metadata": {},
   "source": [
    "変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ca9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"../contents/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c6b1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_path + \"_toc.yml\") as file:\n",
    "    toc_yaml = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a79db7fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file': 'preface'},\n",
       " {'file': 'introduction/intro',\n",
       "  'sections': [{'file': 'introduction/computational-neuroscience'},\n",
       "   {'file': 'introduction/notation'},\n",
       "   {'file': 'introduction/usage-julia-lang'},\n",
       "   {'file': 'introduction/linear-algebra'},\n",
       "   {'file': 'introduction/differential-equation'},\n",
       "   {'file': 'introduction/linear-regression'},\n",
       "   {'file': 'introduction/probability-information-theory'},\n",
       "   {'file': 'introduction/stochastic-process-differential-equation'}]},\n",
       " {'file': 'neuron-model/intro',\n",
       "  'sections': [{'file': 'neuron-model/neuron-physiol'},\n",
       "   {'file': 'neuron-model/hodgkin-huxley'},\n",
       "   {'file': 'neuron-model/fhn'},\n",
       "   {'file': 'neuron-model/lif'},\n",
       "   {'file': 'neuron-model/izhikevich'},\n",
       "   {'file': 'neuron-model/isi'},\n",
       "   {'file': 'neuron-model/neurite-growth-model'}]},\n",
       " {'file': 'synapse-model/intro',\n",
       "  'sections': [{'file': 'synapse-model/synapse-physiol'},\n",
       "   {'file': 'synapse-model/current-conductance-synapse'},\n",
       "   {'file': 'synapse-model/expo-synapse'},\n",
       "   {'file': 'synapse-model/kinetic-synapse'},\n",
       "   {'file': 'synapse-model/synaptic-weighted'},\n",
       "   {'file': 'synapse-model/dynamical-synapses'}]},\n",
       " {'file': 'neuronal-computation/intro',\n",
       "  'sections': [{'file': 'neuronal-computation/neuronal-arithmetic'}]},\n",
       " {'file': 'local-learning-rule/intro',\n",
       "  'sections': [{'file': 'local-learning-rule/pca-hebbian-learning'},\n",
       "   {'file': 'local-learning-rule/mds-anti-hebbian-learning'},\n",
       "   {'file': 'local-learning-rule/slow-feature-analysis'},\n",
       "   {'file': 'local-learning-rule/stdp-learning'},\n",
       "   {'file': 'local-learning-rule/logistic-regression-perceptron'},\n",
       "   {'file': 'local-learning-rule/self-organizing-map'}]},\n",
       " {'file': 'energy-based-model/intro',\n",
       "  'sections': [{'file': 'energy-based-model/energy-based-model'},\n",
       "   {'file': 'energy-based-model/hopfield-model'},\n",
       "   {'file': 'energy-based-model/boltzmann-machine'},\n",
       "   {'file': 'energy-based-model/sparse-coding'},\n",
       "   {'file': 'energy-based-model/predictive-coding'}]},\n",
       " {'file': 'solve-credit-assignment-problem/intro',\n",
       "  'sections': [{'file': 'solve-credit-assignment-problem/backpropagation'},\n",
       "   {'file': 'solve-credit-assignment-problem/linear-network-learning-dynamics'},\n",
       "   {'file': 'solve-credit-assignment-problem/bptt'},\n",
       "   {'file': 'solve-credit-assignment-problem/surrogate-gradient-snn'},\n",
       "   {'file': 'solve-credit-assignment-problem/reservoir-computing'}]},\n",
       " {'file': 'motor-learning/intro',\n",
       "  'sections': [{'file': 'motor-learning/minimum-jerk'},\n",
       "   {'file': 'motor-learning/minimum-variance'},\n",
       "   {'file': 'motor-learning/optimal-feedback-control'},\n",
       "   {'file': 'motor-learning/infinite-horizon-ofc'},\n",
       "   {'file': 'motor-learning/biological-ofc'},\n",
       "   {'file': 'motor-learning/rat-trajectory'}]},\n",
       " {'file': 'reinforcement-learning/intro',\n",
       "  'sections': [{'file': 'reinforcement-learning/td-learning'}]},\n",
       " {'file': 'bayesian-brain/intro',\n",
       "  'sections': [{'file': 'bayesian-brain/neural-uncertainty-representation'},\n",
       "   {'file': 'bayesian-brain/bayesian-linear-regression'},\n",
       "   {'file': 'bayesian-brain/mcmc'},\n",
       "   {'file': 'bayesian-brain/neural-sampling'},\n",
       "   {'file': 'bayesian-brain/probabilistic-population-coding'},\n",
       "   {'file': 'bayesian-brain/quantile-expectile-regression'}]},\n",
       " {'file': 'appendix/intro',\n",
       "  'sections': [{'file': 'appendix/grid-cells-decoding'},\n",
       "   {'file': 'appendix/graph-theory-network-model'},\n",
       "   {'file': 'appendix/useful-links'},\n",
       "   {'file': 'appendix/usage-jupyter-book'}]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc_yaml['sections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c73ef2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_remove(xlist, remove):\n",
    "    return [value for value in xlist if value != remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28bc5fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def md_ipynb2latex(dir_path, filename):\n",
    "    save_dir = \"./text/\" + filename\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    file_path = dir_path + filename\n",
    "    master_list = []\n",
    "    if os.path.isfile(file_path + \".md\"):\n",
    "        f = codecs.open(file_path + \".md\", 'r', encoding=\"utf8\")\n",
    "        md = f.read()\n",
    "        # convert\n",
    "        text = markdown2latex(md)\n",
    "        text = text.split('\\n')\n",
    "        text = latex_itemized(text) #all_remove(text, \"\\n\")\n",
    "        if not \":filter: docname in docnames\" in \"\".join(text):\n",
    "            # save\n",
    "            parted_file_path = save_dir + \"/000.tex\"\n",
    "            with open(parted_file_path, 'w', encoding='UTF-8') as f:\n",
    "                f.writelines(text)\n",
    "                master_list.append(r\"\\input{\"+parted_file_path+\"}\\n\")\n",
    "    elif os.path.isfile(file_path + \".ipynb\"):\n",
    "        f = codecs.open(file_path + \".ipynb\", 'r', encoding=\"utf8\")\n",
    "        source = f.read()\n",
    "        y = json.loads(source)\n",
    "        num_cells = len(y['cells'])\n",
    "        for cell_idx in range(num_cells):\n",
    "            cell = y['cells'][cell_idx]\n",
    "            if cell['cell_type'] == 'markdown':\n",
    "                # convert\n",
    "                text = [markdown2latex(s) for s in cell['source']]\n",
    "                text = latex_itemized(text)\n",
    "                if not \":filter: docname in docnames\" in \"\".join(text):\n",
    "                    # save\n",
    "                    parted_file_path = save_dir + \"/{:03d}.tex\".format(cell_idx)\n",
    "                    with open(parted_file_path, 'w', encoding='UTF-8') as f:\n",
    "                        f.writelines(text)\n",
    "                    master_list.append(r\"\\input{\"+parted_file_path+\"}\\n\")\n",
    "            elif cell['cell_type'] == 'code':\n",
    "                # ToDo:'outputs'\n",
    "                code = cell['source']\n",
    "                parted_file_path = save_dir + \"/{:03d}.jl\".format(cell_idx)\n",
    "                with open(parted_file_path, 'w', encoding='UTF-8') as f:\n",
    "                    f.writelines(code)\n",
    "                master_list.append(r\"\\lstinputlisting[language=julia]{\"+parted_file_path+\"}\\n\")\n",
    "\n",
    "                if cell['outputs']:\n",
    "                    if 'data' in cell['outputs'][0]:\n",
    "                        output = cell['outputs'][0]['data']\n",
    "                        if \"image/png\" in output.keys():\n",
    "                            png_bytes = output['image/png']\n",
    "                            png_bytes = b64decode(png_bytes)\n",
    "                            bytes_io = BytesIO(png_bytes)\n",
    "                            image = Image.open(bytes_io)\n",
    "\n",
    "                            figname = \"cell{:03d}.png\".format(cell_idx)\n",
    "                            figsavepath = \"./fig/\" + filename + \"/\" + figname\n",
    "                            os.makedirs(\"./fig/\" + filename, exist_ok=True)\n",
    "                            image.save(figsavepath, 'png')\n",
    "\n",
    "                            caption = figname\n",
    "                            figlabel = figname #\"ccc\"\n",
    "                            figcode = \"\\\\begin{figure}[ht]\\n\\t\\centering\\n\"\n",
    "                            figcode += \"\\t\\includegraphics[scale=0.8, max width=\\linewidth]{\"+figsavepath+\"}\\n\"\n",
    "                            figcode += \"\\t\\caption{\" + caption + \"}\\n\"\n",
    "                            figcode += \"\\t\\label{\"+figlabel+\"}\\n\"\n",
    "                            figcode += \"\\end{figure}\"\n",
    "\n",
    "                            parted_output_path = save_dir + \"/output_{:03d}.tex\".format(cell_idx)\n",
    "                            with open(parted_output_path, 'w', encoding='UTF-8') as f:\n",
    "                                f.writelines(figcode)\n",
    "                            master_list.append(r\"\\input{\"+parted_output_path+\"}\\n\")\n",
    "                        \n",
    "                        elif \"text/plain\" in output.keys():\n",
    "                            print(output[\"text/plain\"])\n",
    "\n",
    "    with open(save_dir + '.tex', 'w', encoding='UTF-8') as f:\n",
    "        f.writelines(master_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abf941ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03857d91d14645808648bf4b47ddad14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preface\n",
      "introduction/intro\n",
      "introduction/computational-neuroscience\n",
      "introduction/notation\n",
      "introduction/usage-julia-lang\n",
      "['2']\n",
      "['10']\n",
      "['right! (generic function with 1 method)']\n",
      "['foo (generic function with 1 method)']\n",
      "introduction/linear-algebra\n",
      "['3-element Vector{Int64}:\\n', ' 1\\n', ' 2\\n', ' 3']\n",
      "['Any[]']\n",
      "['3×3 Matrix{Float64}:\\n', ' 0.926253  0.353171   0.343478\\n', ' 0.62924   0.0944723  0.917437\\n', ' 0.680284  0.170864   0.654275']\n",
      "['3×3 Matrix{Float64}:\\n', ' 0.414287  0.571006  0.179344\\n', ' 0.281441  0.152742  0.479032\\n', ' 0.304272  0.276252  0.341624']\n",
      "['2×2 Matrix{Int64}:\\n', ' 1  2\\n', ' 3  4']\n",
      "['2×3 Matrix{Int64}:\\n', ' 4  5  6\\n', ' 7  8  9']\n",
      "['2×5 Matrix{Int64}:\\n', ' 1  2  4  5  6\\n', ' 3  4  7  8  9']\n",
      "['2×5 Matrix{Int64}:\\n', ' 1  2  4  5  6\\n', ' 3  4  7  8  9']\n",
      "['2-element Vector{Matrix{Int64}}:\\n', ' [1 2; 3 4]\\n', ' [4 5 6; 7 8 9]']\n",
      "['5×2 Matrix{Int64}:\\n', ' 1  2\\n', ' 3  4\\n', ' 4  7\\n', ' 5  8\\n', ' 6  9']\n",
      "['5×2 Matrix{Int64}:\\n', ' 1  2\\n', ' 3  4\\n', ' 4  7\\n', ' 5  8\\n', ' 6  9']\n",
      "['5×4 Matrix{Int64}:\\n', ' 1  2  1  2\\n', ' 3  4  3  4\\n', ' 4  7  4  7\\n', ' 5  8  5  8\\n', ' 6  9  6  9']\n",
      "['3-element Vector{Float64}:\\n', ' 0.9225597515419179\\n', ' 0.658120481093438\\n', ' 0.41401801671066496']\n",
      "['1×3 Matrix{Float64}:\\n', ' 0.92256  0.65812  0.414018']\n",
      "['UniformScaling{Bool}\\n', 'true*I']\n",
      "['3×3 Diagonal{Bool, Vector{Bool}}:\\n', ' 1  ⋅  ⋅\\n', ' ⋅  1  ⋅\\n', ' ⋅  ⋅  1']\n",
      "['2-element Vector{Float64}:\\n', ' 0.5002132597166149\\n', ' 0.03509562556923285']\n",
      "['2-element Vector{Float64}:\\n', ' -0.1805788303672428\\n', '  0.8082531148175677']\n",
      "['2-element Vector{Float64}:\\n', ' -0.1805788303672428\\n', '  0.8082531148175676']\n",
      "['4×4 Matrix{Float64}:\\n', ' 1.0  5.0   9.0  13.0\\n', ' 2.0  6.0  10.0  14.0\\n', ' 3.0  7.0  11.0  15.0\\n', ' 4.0  8.0  12.0  16.0']\n",
      "['4×4 Matrix{Float64}:\\n', '  25.5193   -29.5701     5.09719  -18.3365\\n', ' -61.7388    71.768    -12.3934    44.6203\\n', '   5.53255   -6.36443    1.09258   -3.92298\\n', '   6.70725   -7.05331    1.14599   -4.0074']\n",
      "['4×4 Matrix{Float64}:\\n', ' 1.0  5.0   9.0  13.0\\n', ' 2.0  6.0  10.0  14.0\\n', ' 3.0  7.0  11.0  15.0\\n', ' 4.0  8.0  12.0  16.0']\n",
      "['2×2×2 Array{Float64, 3}:\\n', '[:, :, 1] =\\n', ' 0.915692  0.18149\\n', ' 0.132838  0.0376235\\n', '\\n', '[:, :, 2] =\\n', ' 0.807789  0.297739\\n', ' 0.569867  0.705417']\n",
      "['8-element Vector{Float64}:\\n', ' 0.9156924090979948\\n', ' 0.13283838898511735\\n', ' 0.18149003405285813\\n', ' 0.03762345094967079\\n', ' 0.8077889408656388\\n', ' 0.5698673388911334\\n', ' 0.297739498855886\\n', ' 0.7054169935372759']\n",
      "['8-element Vector{Float64}:\\n', ' 0.9156924090979948\\n', ' 0.13283838898511735\\n', ' 0.18149003405285813\\n', ' 0.03762345094967079\\n', ' 0.8077889408656388\\n', ' 0.5698673388911334\\n', ' 0.297739498855886\\n', ' 0.7054169935372759']\n",
      "['6×5 Matrix{Float64}:\\n', ' 0.286014   0.923302  0.174386   0.10705    0.744143\\n', ' 0.457232   0.234084  0.149783   0.684196   0.21295\\n', ' 0.308209   0.712286  0.903116   0.487475   6.84179e-6\\n', ' 0.0566201  0.526367  0.235321   0.0381212  0.336639\\n', ' 0.0933628  0.980388  0.0258844  0.0371784  0.849971\\n', ' 0.384149   0.628456  0.077691   0.970843   0.678124']\n",
      "introduction/differential-equation\n",
      "introduction/linear-regression\n",
      "introduction/probability-information-theory\n",
      "introduction/stochastic-process-differential-equation\n",
      "neuron-model/intro\n",
      "neuron-model/neuron-physiol\n",
      "neuron-model/hodgkin-huxley\n",
      "['update! (generic function with 1 method)']\n",
      "neuron-model/fhn\n",
      "['update! (generic function with 1 method)']\n",
      "neuron-model/lif\n",
      "['update! (generic function with 1 method)']\n",
      "neuron-model/izhikevich\n",
      "neuron-model/isi\n",
      "['rasterplot (generic function with 1 method)']\n",
      "['GammaSpike (generic function with 1 method)']\n",
      "['GammaISIplot (generic function with 2 methods)']\n",
      "neuron-model/neurite-growth-model\n",
      "synapse-model/intro\n",
      "synapse-model/synapse-physiol\n",
      "synapse-model/current-conductance-synapse\n",
      "synapse-model/expo-synapse\n",
      "synapse-model/kinetic-synapse\n",
      "['updateHH! (generic function with 1 method)']\n",
      "synapse-model/synaptic-weighted\n",
      "synapse-model/dynamical-synapses\n",
      "neuronal-computation/intro\n",
      "neuronal-computation/neuronal-arithmetic\n",
      "['update! (generic function with 1 method)']\n",
      "['GammaSpike (generic function with 1 method)']\n",
      "['FIcurve (generic function with 3 methods)']\n",
      "['HHIAFIcurve_multi (generic function with 1 method)']\n",
      "local-learning-rule/intro\n",
      "local-learning-rule/pca-hebbian-learning\n",
      "['SVD{Float64, Float64, Matrix{Float64}, Vector{Float64}}\\n', 'U factor:\\n', '2×2 Matrix{Float64}:\\n', ' -0.722509  -0.691362\\n', ' -0.691362   0.722509\\n', 'singular values:\\n', '2-element Vector{Float64}:\\n', ' 418.9073852600819\\n', ' 138.22321877667497\\n', 'Vt factor:\\n', '2×2 Matrix{Float64}:\\n', ' -0.722509  -0.691362\\n', ' -0.691362   0.722509']\n",
      "['DoG (generic function with 6 methods)']\n",
      "['relu (generic function with 1 method)']\n",
      "local-learning-rule/mds-anti-hebbian-learning\n",
      "local-learning-rule/slow-feature-analysis\n",
      "['whiten (generic function with 1 method)']\n",
      "['time_frames (generic function with 1 method)']\n",
      "['linsfa (generic function with 1 method)']\n",
      "local-learning-rule/stdp-learning\n",
      "local-learning-rule/logistic-regression-perceptron\n",
      "['1']\n",
      "['step (generic function with 1 method)']\n",
      "local-learning-rule/self-organizing-map\n",
      "['make_blobs (generic function with 1 method)']\n",
      "['Umatrix2d (generic function with 1 method)']\n",
      "['find_bmu (generic function with 1 method)']\n",
      "energy-based-model/intro\n",
      "energy-based-model/energy-based-model\n",
      "energy-based-model/hopfield-model\n",
      "['corrupted (generic function with 2 methods)']\n",
      "energy-based-model/boltzmann-machine\n",
      "['(28, 28, 60000)']\n",
      "['20']\n",
      "['4']\n",
      "['energy (generic function with 1 method)']\n",
      "energy-based-model/sparse-coding\n",
      "['soft_nonneg_thres (generic function with 1 method)']\n",
      "['updateOF! (generic function with 1 method)']\n",
      "['normalize_rows (generic function with 1 method)']\n",
      "['calculate_total_error (generic function with 1 method)']\n",
      "['run_simulation (generic function with 1 method)']\n",
      "energy-based-model/predictive-coding\n",
      "['update! (generic function with 1 method)']\n",
      "['gaussian_2d (generic function with 4 methods)']\n",
      "['run_simulation (generic function with 1 method)']\n",
      "solve-credit-assignment-problem/intro\n",
      "solve-credit-assignment-problem/backpropagation\n",
      "['optimizer_update! (generic function with 1 method)']\n",
      "['optimizer_update! (generic function with 2 methods)']\n",
      "['update! (generic function with 3 methods)']\n",
      "['Gaussian2d (generic function with 4 methods)']\n",
      "solve-credit-assignment-problem/linear-network-learning-dynamics\n",
      "solve-credit-assignment-problem/bptt\n",
      "['update! (generic function with 1 method)']\n",
      "solve-credit-assignment-problem/surrogate-gradient-snn\n",
      "solve-credit-assignment-problem/reservoir-computing\n",
      "motor-learning/intro\n",
      "motor-learning/minimum-jerk\n",
      "['solveEqualityConstrainedQuadProg (generic function with 1 method)']\n",
      "['6']\n",
      "motor-learning/minimum-variance\n",
      "['minimum_variance_model (generic function with 1 method)']\n",
      "motor-learning/optimal-feedback-control\n",
      "['Reaching1DModelCostParameter']\n",
      "['LQG (generic function with 1 method)']\n",
      "['gLQG (generic function with 3 methods)']\n",
      "['simulation (generic function with 1 method)']\n",
      "['simulation_all (generic function with 1 method)']\n",
      "motor-learning/infinite-horizon-ofc\n",
      "['SaccadeModelParameter']\n",
      "['infinite_horizon_ofc (generic function with 3 methods)']\n",
      "['simulation (generic function with 4 methods)']\n",
      "['1.0']\n",
      "['target_jump_simulation (generic function with 6 methods)']\n",
      "motor-learning/biological-ofc\n",
      "['Reaching1DModelCostParameter']\n",
      "['LQG (generic function with 1 method)']\n",
      "['simulation (generic function with 1 method)']\n",
      "['simulation_all (generic function with 1 method)']\n",
      "motor-learning/rat-trajectory\n",
      "reinforcement-learning/intro\n",
      "reinforcement-learning/td-learning\n",
      "bayesian-brain/intro\n",
      "bayesian-brain/neural-uncertainty-representation\n",
      "bayesian-brain/bayesian-linear-regression\n",
      "bayesian-brain/mcmc\n",
      "['MixtureModel{IsoNormal}(K = 2)\\n', 'components[1] (prior = 0.5000): IsoNormal(\\n', 'dim: 2\\n', 'μ: [0.0, 0.0]\\n', 'Σ: [1.0 0.0; 0.0 1.0]\\n', ')\\n', '\\n', 'components[2] (prior = 0.5000): IsoNormal(\\n', 'dim: 2\\n', 'μ: [3.0, 3.0]\\n', 'Σ: [1.0 0.0; 0.0 1.0]\\n', ')\\n', '\\n']\n",
      "['grad (generic function with 1 method)']\n",
      "['([1.0 0.5551053858555393 … 2.5978715364957816 2.5978715364957816; 0.5 -0.6019397439354577 … 2.2316937524389115 2.2316937524389115], 1191)']\n",
      "['(2, 2000)']\n",
      "['10000']\n",
      "['(0.001, 5.0)']\n",
      "['ulp (generic function with 1 method)']\n",
      "['4-element Vector{Float64}:\\n', '  11.502179436027728\\n', ' -29.136001309910146\\n', ' -28.331966074802352\\n', '   1.0557387545081587']\n",
      "bayesian-brain/neural-sampling\n",
      "['membrane_potential (generic function with 4 methods)']\n",
      "['∇ᵤlogP (generic function with 1 method)']\n",
      "bayesian-brain/probabilistic-population-coding\n",
      "bayesian-brain/quantile-expectile-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['normal_equation (generic function with 1 method)']\n",
      "['kde (generic function with 3 methods)']\n",
      "appendix/intro\n",
      "appendix/grid-cells-decoding\n",
      "['MAT.MAT_v5.Matlabv5File(IOStream(<file ../_static/datasets/grid_cells_data/10704-07070407_T2C3.mat>), false, #undef)']\n",
      "['nearest_pos (generic function with 1 method)']\n",
      "appendix/graph-theory-network-model\n",
      "[\"PyObject <module 'networkx' from 'C:\\\\\\\\Users\\\\\\\\yamta\\\\\\\\miniconda3\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\networkx\\\\\\\\__init__.py'>\"]\n",
      "appendix/useful-links\n",
      "appendix/usage-jupyter-book\n"
     ]
    }
   ],
   "source": [
    "main_list = []\n",
    "for i, section in tqdm(enumerate(toc_yaml['sections'])):\n",
    "    print(section['file']) # intro\n",
    "    if i > 0:\n",
    "        for subsection in section['sections']:\n",
    "            filename = subsection['file']\n",
    "            print(filename)\n",
    "            md_ipynb2latex(dir_path, filename)\n",
    "            main_list.append(r\"\\input{./text/\"+filename+\".tex}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8e3c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"contents_list.tex\", 'w', encoding='UTF-8') as f:\n",
    "    f.writelines(main_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
