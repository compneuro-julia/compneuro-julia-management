\section{神経サンプリング}

サンプリングに基づく符号化(sampling-based coding; SBC or neural sampling model)をガウス尺度混合モデルを例にとり実装する．

\subsection{ガウス尺度混合モデル}
\textbf{ガウス尺度混合 (Gaussian scale mixture; GSM) モデル}は確率的生成モデルの一種である\cite{Wainwright1999-cl}\cite{Orban2016-tm}．GSMモデルでは入力を次式で予測する：


\begin{equation}
\text{入力}={z}\left(\sum \text{神経活動} \times \text{基底} \right) + \text{ノイズ}
\end{equation}


前節までのスパース符号化モデル等と同様に，入力が基底の線形和で表されるとしている．ただし，尺度(scale)パラメータ$z$が基底の線形和に乗じられている点が異なる．\footnote{コードは\cite{Orban2016-tm} \url{https://github.com/gergoorban/sampling_in_gsm}, および\cite{Echeveste2020-sh} \url{https://bitbucket.org/RSE_1987/ssn_inference_numerical_experiments/src/master/}を参考に作成した．}


\subsubsection{事前分布}
$\mathbf{x} \in \mathbb{R}^{N_x}$, $\mathbf{A} \in \mathbb{R}^{N_x\times N_y}$, $\mathbf{y} \in \mathbb{R}^{N_y}$, $\mathbf{z} \in \mathbb{R}$とする．


\begin{equation}
p\left(\mathbf{x}\mid\mathbf{y}, z\right)=\mathcal{N}\left(z \mathbf{A} \mathbf{y}, \sigma_{\mathbf{x}}^{2} \mathbf{I}\right)
\end{equation}


事前分布を


\begin{align}
p\left(\mathbf{y}\right)&=\mathcal{N}\left(\mathbf{0}, \mathbf{C}\right)\\
p\left(z\right)&=\Gamma (k, \vartheta)
\end{align}


とする．$\Gamma(k, \vartheta)$はガンマ分布であり，$k$は形状(shape)パラメータ，$\vartheta$は尺度(scale)パラメータである．$p\left(\mathbf{y}\right)$は$\mathbf{y}$の事前分布であり，刺激がない場合の自発活動の分布を表していると仮定する．
\subsubsection{重み行列$\mathbf{A}$の作成}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/002.jl}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/003.jl}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/004.jl}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/005.jl}
重み行列$\mathbf{A}$の一部を描画してみよう．
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/007.jl}
\input{./text/bayesian-brain/neural-sampling/output_007.tex}
\subsubsection{分散共分散行列$\mathbf{C}$の作成}
$\mathbf{C}$は$y$の事前分布の分散共分散行列である．\cite{Orban2016-tm}では自然画像を用いて作成しているが，ここでは簡単のため$\mathbf{A}$と同様に\cite{Echeveste2020-sh}に従って作成する．前項で作成した通り，$\mathbf{A}$の各基底には周期性があるため，類似した基底を持つニューロン同士は類似した出力をすると考えられる．Echevesteらは$\theta\in[-\pi/2, \pi/2)$の範囲においてFourier基底を複数作成し，そのグラム行列(Gram matrix)を係数倍したものを$\mathbf{C}$と設定している．ここではガウス過程(Gaussian process)モデルとの類似性から，周期カーネル(periodic kernel) 


\begin{equation}
K(\theta, \theta')=\exp\left[\phi_1 \cos \left(\dfrac{|\theta-\theta'|}{\phi_2}\right)\right]
\end{equation}


を用いる．ここでは$|\theta-\theta'|=m\pi\ (m=0,1,\ldots)$の際に類似度が最大になればよいので，$\phi_2=0.5$とする．これが正定値行列になるように単位行列の係数倍$\epsilon\mathbf{I}$を加算し，スケーリングした上で，\jl{Symmetric(C)}や\jl{Matrix(Hermitian(C)))}により実対象行列としたものを$\mathbf{C}$とする．$\mathbf{C}$を正定値行列にする理由はJuliaの\jl{MvNormal}がCholesky分解を用いて多変量正規分布の乱数を生成するためである． 事前に\jl{cholesky(C)}が実行できるか確認するのもよい．
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/009.jl}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/010.jl}
\input{./text/bayesian-brain/neural-sampling/output_010.tex}
ここでPref. oriは最適方位 (preferred orientation)を意味する．
\subsubsection{事後分布の計算}
事後分布は$z$と$\mathbf{y}$のそれぞれについて次のように求められる．



\begin{align}
p(z \mid \mathbf{x}) &\propto p(z) \mathcal{N}\left(0, z^{2} \mathbf{A C A}^{\top}+\sigma_{x}^{2} \mathbf{I}\right)\\
p(\mathbf{y} \mid z, \mathbf{x})& = \mathcal{N}\left(\mu(z, \mathbf{x}), \Sigma(z)\right)
\end{align}


ただし，


\begin{align}
\Sigma(z)&=\left(\mathbf{C}^{-1}+\frac{z^{2}}{\sigma_{x}^{2}} \mathbf{A}^{\top} \mathbf{A}\right)^{-1}\\
\mu(z, \mathbf{x})&=\frac{z}{\sigma_{x}^{2}} \Sigma(z) \mathbf{A}^{\top} \mathbf{x}
\end{align}


である．

最終的な予測において$z$の事後分布は必要でないため，$p(\mathbf{y} \mid z, \mathbf{x})$から$z$を消去することを考えよう．厳密に行う場合，次式のように周辺化(marginalization)により，$z$を (積分) 消去する必要がある．


\begin{equation}
p(\mathbf{y} \mid \mathbf{x}) = \int dz\ p(z\mid \mathbf{x})\cdot p(\mathbf{y} \mid z, \mathbf{x})
\end{equation}


周辺化においては，まず$z$のMAP推定 (最大事後確率推定) 値 $z_{\mathrm{MAP}}$を求める．


\begin{equation}
z_{\mathrm{MAP}} = \underset{z}{\operatorname{argmax}} p(z\mid \mathbf{x})
\end{equation}


次に$z_{\mathrm{MAP}}$の周辺で$p(z\mid \mathbf{x})$を積分し，積分値が一定の閾値を超える$z$の範囲を求め，この範囲で$z$を積分消去してやればよい．しかし，$z$は単一のスカラー値であり，この手法で推定するのは煩雑であるために近似手法が\cite{Echeveste2017-wu}において提案されている．Echevesteらは第一の近似として，$z$の分布を$z_{\mathrm{MAP}}$でのデルタ関数に置き換える，すなわち，$p(z\mid \mathbf{x})\simeq \delta (z-z_{\mathrm{MAP}})$とすることを提案している．この場合，$z$は定数とみなせ，$p(\mathbf{y} \mid \mathbf{x})\simeq p(\mathbf{y} \mid \mathbf{x}, z=z_{\mathrm{MAP}})$となる．第二の近似として，$z_{\mathrm{MAP}}$を真のコントラスト$z^*$で置き換えることが提案されている．GSMへの入力$\mathbf{x}$は元の画像を$\mathbf{\tilde x}$とすると，$\mathbf{x}=z^* \mathbf{\tilde x}$としてスケーリングされる．この入力の前処理の際に用いる$z^*$を用いてしまおうということである．この場合，$p(\mathbf{y} \mid \mathbf{x})\simeq p(\mathbf{y} \mid \mathbf{x}, z=z^*)$となる．しかし，入力を任意の画像とする場合，$z^*$は未知である．簡便さと精度のバランスを取り，ここでは第一の近似，$z=z_{\mathrm{MAP}}$とする手法を用いることにする．
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/013.jl}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/014.jl}
\subsubsection{シミュレーション}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/016.jl}
入力データの作成
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/018.jl}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/019.jl}
\input{./text/bayesian-brain/neural-sampling/output_019.tex}
事後分布の計算をする．
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/021.jl}
\subsubsection{結果}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/023.jl}
\input{./text/bayesian-brain/neural-sampling/output_023.tex}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/024.jl}
\input{./text/bayesian-brain/neural-sampling/output_024.tex}
\subsubsection{出力のサンプリング}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/026.jl}
事後分布から応答をサンプリングする．
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/028.jl}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/029.jl}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/030.jl}
\input{./text/bayesian-brain/neural-sampling/output_030.tex}
\subsection{興奮性・抑制性神経回路によるサンプリング}
前節で実装したMCMCを\textbf{興奮性・抑制性神経回路 (excitatory-inhibitory (E-I) network)} で実装する．HMCとLMCの両方を神経回路で実装する．

Hamiltonianを用いる場合，一般化座標$\mathbf{q}$を興奮性神経細胞の活動$\mathbf{u}$, 一般化運動量$\mathbf{p}$を抑制性神経細胞の活動$\mathbf{v}$に対応させる．ToDo: 詳しい説明.

簡単のため，前項で用いた入力刺激のうち，最も$z$が大きいサンプルのみを使用する．
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/032.jl}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/033.jl}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/034.jl}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/035.jl}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/036.jl}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/037.jl}
初めの100msはburn-in期間として除く．またダウンサンプリングする．
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/039.jl}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/040.jl}
$z$の推定過程を描画する．また，$z$を除いた$\mathbf{u}$を平均化し，自己相関の度合いを確認する．
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/042.jl}
\input{./text/bayesian-brain/neural-sampling/output_042.tex}
Hamiltonianネットワークは自己相関を振動により低下させることで，効率の良いサンプリングを実現している．ToDo: 普通にMCMCやる場合も自己相関は確認したほうがいいという話をどこかに書く．

推定された事後分布を特定の神経細胞のペアについて確認する．
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/044.jl}
\lstinputlisting[language=julia]{./text/bayesian-brain/neural-sampling/045.jl}
\input{./text/bayesian-brain/neural-sampling/output_045.tex}
Hamiltonianネットワークの方が安定して事後分布を推定することができている．ToDo: 以下の記述．ここでは重みを設定したが， \cite{Echeveste2020-sh}ではRNNにBPTTで重みを学習させている．動的な入力に対するサンプリング \cite{Berkes2011-xj}．burn-inがなくなり効率良くサンプリングできる．
\subsection{Spikingニューラルネットワークにおけるサンプリング}
前項で挙げた例は発火率モデルであったが，SNNにおいてサンプリングを実行する機構自体は考案されている．ToDo: 以下の記述．\cite{Buesing2011-dm}\cite{Masset2022-wh}\cite{Zhang2022-bl}
\subsection{シナプスサンプリング}
ここまでシナプス結合強度は変化せず，神経活動の変動によりサンプリングを行うというモデルについて考えてきた．一方で，シナプス結合強度自体が短時間で変動することによりベイズ推論を実行するというモデルがあり，\textbf{シナプスサンプリング(synaptic sampling)} と呼ばれる．ToDo: 以下の記述．\cite{Kappel2015-kq}\cite{Aitchison2021-wo}
