{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896a4096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import re\n",
    "import yaml\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from base64 import b64decode\n",
    "from io import BytesIO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fbc147",
   "metadata": {},
   "source": [
    "同じ文字が連続する場合は長い方から処理する．\n",
    "- ToDo: citationをどうにかする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c0f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '# aa\\n ## aaa\\n `this` is ``` **sample string** for *extracting substring*. {cite:p}`Echeveste2020-sh` <a>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed8dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown2latex(s):\n",
    "    # s: string\n",
    "    s = re.sub(r'\\####\\ (.+?)\\n', r'\\\\paragraph{\\1}\\n', s)  # subsubsection\n",
    "    s = re.sub(r'\\###\\ (.+?)\\n', r'\\\\subsubsection{\\1}\\n', s)  # subsubsection\n",
    "    s = re.sub(r'\\##\\ (.+?)\\n', r'\\\\subsection{\\1}\\n', s)  # subsection\n",
    "    s = re.sub(r'\\#\\ (.+?)\\n', r'\\\\section{\\1}\\n', s)      # section\n",
    "    \n",
    "    s = re.sub(r'\\*\\*(.+?)\\*\\*', r'\\\\textbf{\\1}', s)   # bold\n",
    "    #s = re.sub(r'\\*(.+?)\\*', r'\\\\textit{\\1}', s)       # italic\n",
    "    \n",
    "    s = s.replace(r\"```{note}\", \"\\\\footnote{\") # note to footnote\n",
    "    s = s.replace(r\"```\", \"}\")\n",
    "    s = re.sub(r'<(.+?)>', r'\\\\url{\\1}', s) # url\n",
    "\n",
    "    s = re.sub(r'{cite:p}`(.+?)`', r'\\\\cite{\\1}', s)     \n",
    "    s = re.sub(r'`(.+?)`', r'\\\\jl{\\1}', s) # inline code with \\newcommand{\\jl}{\\lstinline[language=julia]}\n",
    "\n",
    "    s = re.sub(r'<(.+?)>', r'\\\\url{\\1}', s) # url\n",
    "    s = s.replace(r\"（\", \" (\") \n",
    "    s = s.replace(r\"）\", \") \") \n",
    "    s = s.replace(r\"$$\", \"\") \n",
    "    #s = s.replace(r\"．\", \"．\\n\") \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "281faa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_itemized(text):\n",
    "    #splited_text = text.split('\\n')\n",
    "    #splited_text = all_remove(splited_text, \"\\n\")\n",
    "    splited_text = list(filter(None, text))\n",
    "    item_idx = [line[:2] == \"- \" for line in splited_text]\n",
    "    if np.sum(item_idx) > 0:\n",
    "        item_idx += [False]\n",
    "        item_startend = np.where(np.diff(np.array(item_idx)) == True)[0]\n",
    "        item_startend += np.arange(len(item_startend)) + 1\n",
    "\n",
    "        # replace - to \\item\n",
    "        for i in range(len(splited_text)):\n",
    "            if item_idx[i]:\n",
    "                splited_text[i] = splited_text[i].replace('- ', '\\item ', 1) \n",
    "\n",
    "        # add begin and end\n",
    "        for j in range(len(item_startend)):\n",
    "            if j % 2 == 0:\n",
    "                splited_text.insert(item_startend[j], \"\\\\begin{itemize}\")\n",
    "            else:\n",
    "                splited_text.insert(item_startend[j], \"\\\\end{itemize}\")\n",
    "    for i in range(len(splited_text)):\n",
    "        if splited_text[i][-1:] != \"\\n\":\n",
    "            splited_text[i] += \"\\n\"\n",
    "    return splited_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39487f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\section{aa}\\n \\\\subsection{aaa}\\n \\\\jl{this} is } \\\\textbf{sample string} for *extracting substring*. \\\\cite{Echeveste2020-sh} \\\\url{a}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown2latex(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f606d4",
   "metadata": {},
   "source": [
    "変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ca9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"../contents/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c6b1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_path + \"_toc.yml\") as file:\n",
    "    toc_yaml = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a79db7fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file': 'preface'},\n",
       " {'file': 'introduction/intro',\n",
       "  'sections': [{'file': 'introduction/computational-neuroscience'},\n",
       "   {'file': 'introduction/notation'},\n",
       "   {'file': 'introduction/usage-julia-lang'},\n",
       "   {'file': 'introduction/linear-algebra'},\n",
       "   {'file': 'introduction/differential-equation'},\n",
       "   {'file': 'introduction/linear-regression'},\n",
       "   {'file': 'introduction/probability-information-theory'},\n",
       "   {'file': 'introduction/stochastic-process-differential-equation'}]},\n",
       " {'file': 'neuron-model/intro',\n",
       "  'sections': [{'file': 'neuron-model/neuron-physiol'},\n",
       "   {'file': 'neuron-model/hodgkin-huxley'},\n",
       "   {'file': 'neuron-model/fhn'},\n",
       "   {'file': 'neuron-model/lif'},\n",
       "   {'file': 'neuron-model/izhikevich'},\n",
       "   {'file': 'neuron-model/isi'},\n",
       "   {'file': 'neuron-model/neurite-growth-model'}]},\n",
       " {'file': 'synapse-model/intro',\n",
       "  'sections': [{'file': 'synapse-model/synapse-physiol'},\n",
       "   {'file': 'synapse-model/current-conductance-synapse'},\n",
       "   {'file': 'synapse-model/expo-synapse'},\n",
       "   {'file': 'synapse-model/kinetic-synapse'},\n",
       "   {'file': 'synapse-model/synaptic-weighted'},\n",
       "   {'file': 'synapse-model/dynamical-synapses'}]},\n",
       " {'file': 'neuronal-computation/intro',\n",
       "  'sections': [{'file': 'neuronal-computation/neuronal-arithmetic'}]},\n",
       " {'file': 'local-learning-rule/intro',\n",
       "  'sections': [{'file': 'local-learning-rule/pca-hebbian-learning'},\n",
       "   {'file': 'local-learning-rule/mds-anti-hebbian-learning'},\n",
       "   {'file': 'local-learning-rule/slow-feature-analysis'},\n",
       "   {'file': 'local-learning-rule/stdp-learning'},\n",
       "   {'file': 'local-learning-rule/logistic-regression-perceptron'},\n",
       "   {'file': 'local-learning-rule/self-organizing-map'}]},\n",
       " {'file': 'energy-based-model/intro',\n",
       "  'sections': [{'file': 'energy-based-model/energy-based-model'},\n",
       "   {'file': 'energy-based-model/hopfield-model'},\n",
       "   {'file': 'energy-based-model/boltzmann-machine'},\n",
       "   {'file': 'energy-based-model/sparse-coding'},\n",
       "   {'file': 'energy-based-model/predictive-coding'}]},\n",
       " {'file': 'solve-credit-assignment-problem/intro',\n",
       "  'sections': [{'file': 'solve-credit-assignment-problem/backpropagation'},\n",
       "   {'file': 'solve-credit-assignment-problem/linear-network-learning-dynamics'},\n",
       "   {'file': 'solve-credit-assignment-problem/bptt'},\n",
       "   {'file': 'solve-credit-assignment-problem/surrogate-gradient-snn'},\n",
       "   {'file': 'solve-credit-assignment-problem/reservoir-computing'}]},\n",
       " {'file': 'motor-learning/intro',\n",
       "  'sections': [{'file': 'motor-learning/minimum-jerk'},\n",
       "   {'file': 'motor-learning/minimum-variance'},\n",
       "   {'file': 'motor-learning/optimal-feedback-control'},\n",
       "   {'file': 'motor-learning/infinite-horizon-ofc'},\n",
       "   {'file': 'motor-learning/biological-ofc'},\n",
       "   {'file': 'motor-learning/rat-trajectory'}]},\n",
       " {'file': 'reinforcement-learning/intro',\n",
       "  'sections': [{'file': 'reinforcement-learning/td-learning'}]},\n",
       " {'file': 'bayesian-brain/intro',\n",
       "  'sections': [{'file': 'bayesian-brain/neural-uncertainty-representation'},\n",
       "   {'file': 'bayesian-brain/bayesian-linear-regression'},\n",
       "   {'file': 'bayesian-brain/mcmc'},\n",
       "   {'file': 'bayesian-brain/neural-sampling'},\n",
       "   {'file': 'bayesian-brain/probabilistic-population-coding'},\n",
       "   {'file': 'bayesian-brain/quantile-expectile-regression'}]},\n",
       " {'file': 'appendix/intro',\n",
       "  'sections': [{'file': 'appendix/grid-cells-decoding'},\n",
       "   {'file': 'appendix/graph-theory-network-model'},\n",
       "   {'file': 'appendix/useful-links'},\n",
       "   {'file': 'appendix/usage-jupyter-book'}]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc_yaml['sections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c73ef2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_remove(xlist, remove):\n",
    "    return [value for value in xlist if value != remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28bc5fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def md_ipynb2latex(dir_path, filename):\n",
    "    save_dir = \"./text/\" + filename\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    file_path = dir_path + filename\n",
    "    master_list = []\n",
    "    if os.path.isfile(file_path + \".md\"):\n",
    "        f = codecs.open(file_path + \".md\", 'r', encoding=\"utf8\")\n",
    "        md = f.read()\n",
    "        # convert\n",
    "        text = markdown2latex(md)\n",
    "        text = text.split('\\n')\n",
    "        text = latex_itemized(text) #all_remove(text, \"\\n\")\n",
    "        if not \":filter: docname in docnames\" in \"\".join(text):\n",
    "            # save\n",
    "            parted_file_path = save_dir + \"/000.tex\"\n",
    "            with open(parted_file_path, 'w', encoding='UTF-8') as f:\n",
    "                f.writelines(text)\n",
    "                master_list.append(r\"\\input{\"+parted_file_path+\"}\\n\")\n",
    "    elif os.path.isfile(file_path + \".ipynb\"):\n",
    "        f = codecs.open(file_path + \".ipynb\", 'r', encoding=\"utf8\")\n",
    "        source = f.read()\n",
    "        y = json.loads(source)\n",
    "        num_cells = len(y['cells'])\n",
    "        for cell_idx in range(num_cells):\n",
    "            cell = y['cells'][cell_idx]\n",
    "            if cell['cell_type'] == 'markdown':\n",
    "                # convert\n",
    "                text = [markdown2latex(s) for s in cell['source']]\n",
    "                text = latex_itemized(text)\n",
    "                if not \":filter: docname in docnames\" in \"\".join(text):\n",
    "                    # save\n",
    "                    parted_file_path = save_dir + \"/{:03d}.tex\".format(cell_idx)\n",
    "                    with open(parted_file_path, 'w', encoding='UTF-8') as f:\n",
    "                        f.writelines(text)\n",
    "                    master_list.append(r\"\\input{\"+parted_file_path+\"}\\n\")\n",
    "            elif cell['cell_type'] == 'code':\n",
    "                # ToDo:'outputs'\n",
    "                code = cell['source']\n",
    "                parted_file_path = save_dir + \"/{:03d}.jl\".format(cell_idx)\n",
    "                with open(parted_file_path, 'w', encoding='UTF-8') as f:\n",
    "                    f.writelines(code)\n",
    "                master_list.append(r\"\\lstinputlisting[language=julia]{\"+parted_file_path+\"}\\n\")\n",
    "\n",
    "                if cell['outputs']:\n",
    "                    if 'data' in cell['outputs'][0]:\n",
    "                        output = cell['outputs'][0]['data']\n",
    "                        if \"image/png\" in output.keys():\n",
    "                            png_bytes = output['image/png']\n",
    "                            png_bytes = b64decode(png_bytes)\n",
    "                            bytes_io = BytesIO(png_bytes)\n",
    "                            image = Image.open(bytes_io)\n",
    "\n",
    "                            figname = \"cell{:03d}.png\".format(cell_idx)\n",
    "                            figsavepath = \"./fig/\" + filename + \"/\" + figname\n",
    "                            os.makedirs(\"./fig/\" + filename, exist_ok=True)\n",
    "                            image.save(figsavepath, 'png')\n",
    "\n",
    "                            caption = figname\n",
    "                            figlabel = figname #\"ccc\"\n",
    "                            figcode = \"\\\\begin{figure}[ht]\\n\\t\\centering\\n\"\n",
    "                            figcode += \"\\t\\includegraphics[scale=0.8, max width=\\linewidth]{\"+figsavepath+\"}\\n\"\n",
    "                            figcode += \"\\t\\caption{\" + caption + \"}\\n\"\n",
    "                            figcode += \"\\t\\label{\"+figlabel+\"}\\n\"\n",
    "                            figcode += \"\\end{figure}\"\n",
    "\n",
    "                            parted_output_path = save_dir + \"/output_{:03d}.tex\".format(cell_idx)\n",
    "                            with open(parted_output_path, 'w', encoding='UTF-8') as f:\n",
    "                                f.writelines(figcode)\n",
    "                            master_list.append(r\"\\input{\"+parted_output_path+\"}\\n\")\n",
    "                        \n",
    "                        elif \"text/plain\" in output.keys():\n",
    "                            print(output[\"text/plain\"])\n",
    "\n",
    "    with open(save_dir + '.tex', 'w', encoding='UTF-8') as f:\n",
    "        f.writelines(master_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abf941ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80767d37f0d450db2e5fff7b4cb51c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preface\n",
      "introduction/intro\n",
      "introduction/computational-neuroscience\n",
      "introduction/notation\n",
      "introduction/usage-julia-lang\n",
      "['2']\n",
      "['10']\n",
      "['right! (generic function with 1 method)']\n",
      "['foo (generic function with 1 method)']\n",
      "introduction/linear-algebra\n",
      "['3-element Vector{Int64}:\\n', ' 1\\n', ' 2\\n', ' 3']\n",
      "['Any[]']\n",
      "['3×3 Matrix{Float64}:\\n', ' 0.926253  0.353171   0.343478\\n', ' 0.62924   0.0944723  0.917437\\n', ' 0.680284  0.170864   0.654275']\n",
      "['3×3 Matrix{Float64}:\\n', ' 0.414287  0.571006  0.179344\\n', ' 0.281441  0.152742  0.479032\\n', ' 0.304272  0.276252  0.341624']\n",
      "['2×2 Matrix{Int64}:\\n', ' 1  2\\n', ' 3  4']\n",
      "['2×3 Matrix{Int64}:\\n', ' 4  5  6\\n', ' 7  8  9']\n",
      "['2×5 Matrix{Int64}:\\n', ' 1  2  4  5  6\\n', ' 3  4  7  8  9']\n",
      "['2×5 Matrix{Int64}:\\n', ' 1  2  4  5  6\\n', ' 3  4  7  8  9']\n",
      "['2-element Vector{Matrix{Int64}}:\\n', ' [1 2; 3 4]\\n', ' [4 5 6; 7 8 9]']\n",
      "['5×2 Matrix{Int64}:\\n', ' 1  2\\n', ' 3  4\\n', ' 4  7\\n', ' 5  8\\n', ' 6  9']\n",
      "['5×2 Matrix{Int64}:\\n', ' 1  2\\n', ' 3  4\\n', ' 4  7\\n', ' 5  8\\n', ' 6  9']\n",
      "['5×4 Matrix{Int64}:\\n', ' 1  2  1  2\\n', ' 3  4  3  4\\n', ' 4  7  4  7\\n', ' 5  8  5  8\\n', ' 6  9  6  9']\n",
      "['3-element Vector{Float64}:\\n', ' 0.9225597515419179\\n', ' 0.658120481093438\\n', ' 0.41401801671066496']\n",
      "['1×3 Matrix{Float64}:\\n', ' 0.92256  0.65812  0.414018']\n",
      "['UniformScaling{Bool}\\n', 'true*I']\n",
      "['3×3 Diagonal{Bool, Vector{Bool}}:\\n', ' 1  ⋅  ⋅\\n', ' ⋅  1  ⋅\\n', ' ⋅  ⋅  1']\n",
      "['2-element Vector{Float64}:\\n', ' 0.5002132597166149\\n', ' 0.03509562556923285']\n",
      "['2-element Vector{Float64}:\\n', ' -0.1805788303672428\\n', '  0.8082531148175677']\n",
      "['2-element Vector{Float64}:\\n', ' -0.1805788303672428\\n', '  0.8082531148175676']\n",
      "['4×4 Matrix{Float64}:\\n', ' 1.0  5.0   9.0  13.0\\n', ' 2.0  6.0  10.0  14.0\\n', ' 3.0  7.0  11.0  15.0\\n', ' 4.0  8.0  12.0  16.0']\n",
      "['4×4 Matrix{Float64}:\\n', '  25.5193   -29.5701     5.09719  -18.3365\\n', ' -61.7388    71.768    -12.3934    44.6203\\n', '   5.53255   -6.36443    1.09258   -3.92298\\n', '   6.70725   -7.05331    1.14599   -4.0074']\n",
      "['4×4 Matrix{Float64}:\\n', ' 1.0  5.0   9.0  13.0\\n', ' 2.0  6.0  10.0  14.0\\n', ' 3.0  7.0  11.0  15.0\\n', ' 4.0  8.0  12.0  16.0']\n",
      "['2×2×2 Array{Float64, 3}:\\n', '[:, :, 1] =\\n', ' 0.915692  0.18149\\n', ' 0.132838  0.0376235\\n', '\\n', '[:, :, 2] =\\n', ' 0.807789  0.297739\\n', ' 0.569867  0.705417']\n",
      "['8-element Vector{Float64}:\\n', ' 0.9156924090979948\\n', ' 0.13283838898511735\\n', ' 0.18149003405285813\\n', ' 0.03762345094967079\\n', ' 0.8077889408656388\\n', ' 0.5698673388911334\\n', ' 0.297739498855886\\n', ' 0.7054169935372759']\n",
      "['8-element Vector{Float64}:\\n', ' 0.9156924090979948\\n', ' 0.13283838898511735\\n', ' 0.18149003405285813\\n', ' 0.03762345094967079\\n', ' 0.8077889408656388\\n', ' 0.5698673388911334\\n', ' 0.297739498855886\\n', ' 0.7054169935372759']\n",
      "['6×5 Matrix{Float64}:\\n', ' 0.286014   0.923302  0.174386   0.10705    0.744143\\n', ' 0.457232   0.234084  0.149783   0.684196   0.21295\\n', ' 0.308209   0.712286  0.903116   0.487475   6.84179e-6\\n', ' 0.0566201  0.526367  0.235321   0.0381212  0.336639\\n', ' 0.0933628  0.980388  0.0258844  0.0371784  0.849971\\n', ' 0.384149   0.628456  0.077691   0.970843   0.678124']\n",
      "introduction/differential-equation\n",
      "introduction/linear-regression\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './fig/introduction/linear-regression/cell007.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m filename \u001b[38;5;241m=\u001b[39m subsection[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(filename)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmd_ipynb2latex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m main_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m./text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfilename\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tex}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 56\u001b[0m, in \u001b[0;36mmd_ipynb2latex\u001b[1;34m(dir_path, filename)\u001b[0m\n\u001b[0;32m     54\u001b[0m figsavepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./fig/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m filename \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m figname\n\u001b[0;32m     55\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./fig/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m filename, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 56\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigsavepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m caption \u001b[38;5;241m=\u001b[39m figname\n\u001b[0;32m     59\u001b[0m figlabel \u001b[38;5;241m=\u001b[39m figname \u001b[38;5;66;03m#\"ccc\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:2429\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2427\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2428\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2429\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2431\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2432\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './fig/introduction/linear-regression/cell007.png'"
     ]
    }
   ],
   "source": [
    "main_list = []\n",
    "for i, section in tqdm(enumerate(toc_yaml['sections'])):\n",
    "    print(section['file']) # intro\n",
    "    if i > 0:\n",
    "        for subsection in section['sections']:\n",
    "            filename = subsection['file']\n",
    "            print(filename)\n",
    "            md_ipynb2latex(dir_path, filename)\n",
    "            main_list.append(r\"\\input{./text/\"+filename+\".tex}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e3c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"contents_list.tex\", 'w', encoding='UTF-8') as f:\n",
    "    f.writelines(main_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
