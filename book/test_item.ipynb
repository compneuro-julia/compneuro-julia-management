{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896a4096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import re\n",
    "import yaml\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from base64 import b64decode\n",
    "from io import BytesIO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fbc147",
   "metadata": {},
   "source": [
    "同じ文字が連続する場合は長い方から処理する．\n",
    "- ToDo: citationをどうにかする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8c0f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '# aa\\n ## aaa\\n `this` is ``` **sample string** for *extracting substring*. {cite:p}`Echeveste2020-sh` <a>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed8dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown2latex(s):\n",
    "    # s: string\n",
    "    s = re.sub(r'\\###\\ (.+?)\\n', r'\\\\subsubsection{\\1}', s)  # subsubsection\n",
    "    s = re.sub(r'\\##\\ (.+?)\\n', r'\\\\subsection{\\1}', s)  # subsection\n",
    "    s = re.sub(r'\\#\\ (.+?)\\n', r'\\\\section{\\1}', s)      # section\n",
    "    \n",
    "    s = re.sub(r'\\*\\*(.+?)\\*\\*', r'\\\\textbf{\\1}', s)   # bold\n",
    "    #s = re.sub(r'\\*(.+?)\\*', r'\\\\textit{\\1}', s)       # italic\n",
    "    \n",
    "    s = s.replace(r\"```{note}\", \"\\\\footnote{\") # note to footnote\n",
    "    s = s.replace(r\"```\", \"}\")\n",
    "    s = re.sub(r'<(.+?)>', r'\\\\url{\\1}', s) # url\n",
    "\n",
    "    s = re.sub(r'{cite:p}`(.+?)`', r'\\\\cite{\\1}', s)     \n",
    "    s = re.sub(r'`(.+?)`', r'\\\\jl{\\1}', s) # inline code with \\newcommand{\\jl}{\\lstinline[language=julia]}\n",
    "\n",
    "    s = re.sub(r'<(.+?)>', r'\\\\url{\\1}', s) # url\n",
    "    s = s.replace(r\"（\", \" (\") \n",
    "    s = s.replace(r\"）\", \") \") \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39487f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\section{aa} \\\\subsection{aaa} \\\\jl{this} is } \\\\textbf{sample string} for *extracting substring*. \\\\cite{Echeveste2020-sh} \\\\url{a}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown2latex(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f606d4",
   "metadata": {},
   "source": [
    "変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ca9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"../contents/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c6b1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_path + \"_toc.yml\") as file:\n",
    "    toc_yaml = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a79db7fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file': 'preface'},\n",
       " {'file': 'introduction/intro',\n",
       "  'sections': [{'file': 'introduction/computational-neuroscience'},\n",
       "   {'file': 'introduction/notation'},\n",
       "   {'file': 'introduction/usage-julia-lang'},\n",
       "   {'file': 'introduction/linear-algebra'},\n",
       "   {'file': 'introduction/differential-equation'},\n",
       "   {'file': 'introduction/linear-regression'},\n",
       "   {'file': 'introduction/probability-information-theory'},\n",
       "   {'file': 'introduction/stochastic-process-differential-equation'}]},\n",
       " {'file': 'neuron-model/intro',\n",
       "  'sections': [{'file': 'neuron-model/neuron-physiol'},\n",
       "   {'file': 'neuron-model/hodgkin-huxley'},\n",
       "   {'file': 'neuron-model/fhn'},\n",
       "   {'file': 'neuron-model/lif'},\n",
       "   {'file': 'neuron-model/izhikevich'},\n",
       "   {'file': 'neuron-model/isi'},\n",
       "   {'file': 'neuron-model/neurite-growth-model'}]},\n",
       " {'file': 'synapse-model/intro',\n",
       "  'sections': [{'file': 'synapse-model/synapse-physiol'},\n",
       "   {'file': 'synapse-model/current-conductance-synapse'},\n",
       "   {'file': 'synapse-model/expo-synapse'},\n",
       "   {'file': 'synapse-model/kinetic-synapse'},\n",
       "   {'file': 'synapse-model/synaptic-weighted'},\n",
       "   {'file': 'synapse-model/dynamical-synapses'}]},\n",
       " {'file': 'neuronal-computation/intro',\n",
       "  'sections': [{'file': 'neuronal-computation/neuronal-arithmetic'}]},\n",
       " {'file': 'local-learning-rule/intro',\n",
       "  'sections': [{'file': 'local-learning-rule/pca-hebbian-learning'},\n",
       "   {'file': 'local-learning-rule/mds-anti-hebbian-learning'},\n",
       "   {'file': 'local-learning-rule/slow-feature-analysis'},\n",
       "   {'file': 'local-learning-rule/stdp-learning'},\n",
       "   {'file': 'local-learning-rule/logistic-regression-perceptron'},\n",
       "   {'file': 'local-learning-rule/self-organizing-map'}]},\n",
       " {'file': 'energy-based-model/intro',\n",
       "  'sections': [{'file': 'energy-based-model/energy-based-model'},\n",
       "   {'file': 'energy-based-model/hopfield-model'},\n",
       "   {'file': 'energy-based-model/boltzmann-machine'},\n",
       "   {'file': 'energy-based-model/sparse-coding'},\n",
       "   {'file': 'energy-based-model/predictive-coding'}]},\n",
       " {'file': 'solve-credit-assignment-problem/intro',\n",
       "  'sections': [{'file': 'solve-credit-assignment-problem/backpropagation'},\n",
       "   {'file': 'solve-credit-assignment-problem/linear-network-learning-dynamics'},\n",
       "   {'file': 'solve-credit-assignment-problem/bptt'},\n",
       "   {'file': 'solve-credit-assignment-problem/surrogate-gradient-snn'},\n",
       "   {'file': 'solve-credit-assignment-problem/reservoir-computing'}]},\n",
       " {'file': 'motor-learning/intro',\n",
       "  'sections': [{'file': 'motor-learning/minimum-jerk'},\n",
       "   {'file': 'motor-learning/minimum-variance'},\n",
       "   {'file': 'motor-learning/optimal-feedback-control'},\n",
       "   {'file': 'motor-learning/infinite-horizon-ofc'},\n",
       "   {'file': 'motor-learning/biological-ofc'},\n",
       "   {'file': 'motor-learning/rat-trajectory'}]},\n",
       " {'file': 'reinforcement-learning/intro',\n",
       "  'sections': [{'file': 'reinforcement-learning/td-learning'}]},\n",
       " {'file': 'bayesian-brain/intro',\n",
       "  'sections': [{'file': 'bayesian-brain/neural-uncertainty-representation'},\n",
       "   {'file': 'bayesian-brain/bayesian-linear-regression'},\n",
       "   {'file': 'bayesian-brain/mcmc'},\n",
       "   {'file': 'bayesian-brain/neural-sampling'},\n",
       "   {'file': 'bayesian-brain/probabilistic-population-coding'},\n",
       "   {'file': 'bayesian-brain/quantile-expectile-regression'}]},\n",
       " {'file': 'appendix/intro',\n",
       "  'sections': [{'file': 'appendix/grid-cells-decoding'},\n",
       "   {'file': 'appendix/graph-theory-network-model'},\n",
       "   {'file': 'appendix/useful-links'},\n",
       "   {'file': 'appendix/usage-jupyter-book'}]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc_yaml['sections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c73ef2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_remove(xlist, remove):\n",
    "        return [value for value in xlist if value != remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28bc5fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def md_ipynb2latex(dir_path, filename):\n",
    "    save_dir = \"./text/\" + filename\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    file_path = dir_path + filename\n",
    "    master_list = []\n",
    "    if os.path.isfile(file_path + \".md\"):\n",
    "        f = codecs.open(file_path + \".md\", 'r', encoding=\"utf8\")\n",
    "        md = f.read()\n",
    "        # convert\n",
    "        text = markdown2latex(md)\n",
    "        text = all_remove(text, \"\\n\")\n",
    "        if not ':filter: docname in docnames\\n' in text:\n",
    "            # save\n",
    "            parted_file_path = save_dir + \"/000.tex\"\n",
    "            with open(parted_file_path, 'w', encoding='UTF-8') as f:\n",
    "                f.writelines(text)\n",
    "                master_list.append(r\"\\input{\"+parted_file_path+\"}\\n\")\n",
    "    elif os.path.isfile(file_path + \".ipynb\"):\n",
    "        f = codecs.open(file_path + \".ipynb\", 'r', encoding=\"utf8\")\n",
    "        source = f.read()\n",
    "        y = json.loads(source)\n",
    "        num_cells = len(y['cells'])\n",
    "        for cell_idx in range(num_cells):\n",
    "            cell = y['cells'][cell_idx]\n",
    "            if cell['cell_type'] == 'markdown':\n",
    "                # convert\n",
    "                text = [markdown2latex(s) for s in cell['source']]\n",
    "                text = all_remove(text, \"\\n\")\n",
    "                if not ':filter: docname in docnames\\n' in text:\n",
    "                    # save\n",
    "                    parted_file_path = save_dir + \"/{:03d}.tex\".format(cell_idx)\n",
    "                    with open(parted_file_path, 'w', encoding='UTF-8') as f:\n",
    "                        f.writelines(text)\n",
    "                    master_list.append(r\"\\input{\"+parted_file_path+\"}\\n\")\n",
    "            elif cell['cell_type'] == 'code':\n",
    "                # ToDo:'outputs'\n",
    "                code = cell['source']\n",
    "                parted_file_path = save_dir + \"/{:03d}.jl\".format(cell_idx)\n",
    "                with open(parted_file_path, 'w', encoding='UTF-8') as f:\n",
    "                    f.writelines(code)\n",
    "                master_list.append(r\"\\lstinputlisting[language=julia]{\"+parted_file_path+\"}\\n\")\n",
    "\n",
    "                if cell['outputs']:\n",
    "                    if 'data' in cell['outputs'][0]:\n",
    "                        output = cell['outputs'][0]['data']\n",
    "                        if \"image/png\" in output.keys():\n",
    "                            png_bytes = output['image/png']\n",
    "                            png_bytes = b64decode(png_bytes)\n",
    "                            bytes_io = BytesIO(png_bytes)\n",
    "                            image = Image.open(bytes_io)\n",
    "\n",
    "                            figname = \"cell{:03d}.png\".format(cell_idx)\n",
    "                            figsavepath = \"./fig/\" + filename + \"/\" + figname\n",
    "                            os.makedirs(\"./fig/\" + filename, exist_ok=True)\n",
    "                            image.save(figsavepath, 'png')\n",
    "\n",
    "                            caption = figname\n",
    "                            figlabel = figname #\"ccc\"\n",
    "                            figcode = \"\\\\begin{figure}[ht]\\n\\t\\centering\\n\"\n",
    "                            figcode += \"\\t\\includegraphics[scale=0.8, max width=\\linewidth]{\"+figsavepath+\"}\\n\"\n",
    "                            figcode += \"\\t\\caption{\" + caption + \"}\\n\"\n",
    "                            figcode += \"\\t\\label{\"+figlabel+\"}\\n\"\n",
    "                            figcode += \"\\end{figure}\"\n",
    "\n",
    "                            parted_output_path = save_dir + \"/output_{:03d}.tex\".format(cell_idx)\n",
    "                            with open(parted_output_path, 'w', encoding='UTF-8') as f:\n",
    "                                f.writelines(figcode)\n",
    "                            master_list.append(r\"\\input{\"+parted_output_path+\"}\\n\")\n",
    "                        \n",
    "                        elif \"text/plain\" in output.keys():\n",
    "                            print(output[\"text/plain\"])\n",
    "\n",
    "    with open(save_dir + '.tex', 'w', encoding='UTF-8') as f:\n",
    "        f.writelines(master_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c19b8cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_itemized(text):\n",
    "    #splited_text = text.split('\\n')\n",
    "    #splited_text = all_remove(splited_text, \"\\n\")\n",
    "    splited_text = list(filter(None, text))\n",
    "    item_idx = [line[0] == \"-\" for line in splited_text]\n",
    "    if np.sum(item_idx) > 0:\n",
    "        item_idx += [False]\n",
    "        item_startend = np.where(np.diff(np.array(item_idx)) == True)[0]\n",
    "        item_startend += np.arange(len(item_startend)) + 1\n",
    "\n",
    "        # replace - to \\item\n",
    "        for i in range(len(splited_text)):\n",
    "            if item_idx[i]:\n",
    "                splited_text[i] = splited_text[i].replace('-', '\\item', 1) \n",
    "\n",
    "        # add begin and end\n",
    "        for j in range(len(item_startend)):\n",
    "            if j % 2 == 0:\n",
    "                splited_text.insert(item_startend[j], \"\\\\begin{itemize}\")\n",
    "            else:\n",
    "                splited_text.insert(item_startend[j], \"\\\\end{itemize}\")\n",
    "    #text2 = '\\n'.join(splited_text)\n",
    "    for i in range(len(splited_text)):\n",
    "        if splited_text[i][-1:] != \"\\n\":\n",
    "            splited_text[i] += \"\\n\"\n",
    "    return splited_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "819033cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"introduction/notation\"\n",
    "file_path = dir_path + filename\n",
    "f = codecs.open(file_path + \".md\", 'r', encoding=\"utf8\")\n",
    "md = f.read()\n",
    "text = markdown2latex(md)\n",
    "text = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "75916b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\section{記号の表記}',\n",
       " '本書では次のような記号表記を用いる．',\n",
       " '- 実数全体を$\\\\mathbb{R}$, 複素数全体は$\\\\mathbb{C}$と表記する．',\n",
       " '- スカラーは小文字・斜体で $x$ のように表記する．',\n",
       " '- ベクトルは小文字・立体・太字で $\\\\mathbf{x}$ のように表記し，列ベクトル (縦ベクトル) として扱う．',\n",
       " '- 行列は大文字・立体・太字で $\\\\mathbf{X}$ のように表記する．',\n",
       " '- $n\\\\times 1$の実ベクトルの集合を $\\\\mathbb{R}^n$, $n\\\\times m$ の実行列の集合を $\\\\mathbb{R}^{n\\\\times m}$と表記する．',\n",
       " '- 行列 $\\\\mathbf{X}$ の置換は $\\\\mathbf{X}^\\\\top$と表記する．ベクトルの要素を表す場合は $\\\\mathbf{x} = (x_1, x_2,\\\\cdots, x_n)^\\\\top$のように表記する．',\n",
       " '- 単位行列を $\\\\mathbf{I}$ と表記する．',\n",
       " '- ゼロベクトルは $\\\\mathbf{0}$ , 要素が全て1のベクトルは $\\\\mathbf{1}$ と表記する．  ',\n",
       " '- $e$を自然対数の底とし，指数関数を $e^x=\\\\exp(x)$と表記する．また，自然対数を $\\\\ln(x)$と表記する．',\n",
       " '- 定義を$:=$を用いて行う．例えば，$f(x):=2x$は$f(x)$という関数を$2x$として定義するという意味である．',\n",
       " '- 平均 $\\\\mu$, 標準偏差 $\\\\sigma$ の正規分布を $\\\\mathcal{N}(\\\\mu, \\\\sigma^2)$ と表記する．',\n",
       " '',\n",
       " '\\\\subsection{変数の命名規則}',\n",
       " '- \\\\jl{tp1, tm1} : time plus one (t+1), time minus one (t-1)']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "621563a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5998fa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"energy-based-model/predictive-coding\"\n",
    "file_path = dir_path + filename\n",
    "f = codecs.open(file_path + \".ipynb\", 'r', encoding=\"utf8\")\n",
    "source = f.read()\n",
    "y = json.loads(source)\n",
    "num_cells = len(y['cells'])\n",
    "cell_idx = 10\n",
    "cell = y['cells'][cell_idx]\n",
    "text = [markdown2latex(s) for s in cell['source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2cf6c86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tex2 = latex_itemized(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fbb86e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\":filter: docname in docnames\" in \"\".join(tex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e84d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a814943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\section{予測符号化}\\n',\n",
       " '\\\\subsection{観測世界の階層的予測}\\n',\n",
       " '\\\\textbf{階層的予測符号化(hierarchical predictive coding; HPC)} は\\\\cite{Rao1999-zv}により導入された．構築するネットワークは入力層を含め，3層のネットワークとする．LGNへの入力として画像 $\\\\mathbf{x} \\\\in \\\\mathbb{R}^{n_0}$を考える．画像 $\\\\mathbf{x}$ の観測世界における隠れ変数，すなわち\\\\textbf{潜在変数} (latent variable)を$\\\\mathbf{r} \\\\in \\\\mathbb{R}^{n_1}$とし，ニューロン群によって発火率で表現されているとする (真の変数と $\\\\mathbf{r}$は異なるので文字を分けるべきだが簡単のためにこう表す)．このとき，\\n',\n",
       " '\\n',\n",
       " '$$\\n',\n",
       " '\\\\mathbf{x} = f(\\\\mathbf{U}\\\\mathbf{r}) + \\\\boldsymbol{\\\\epsilon} \\\\tag{1}\\n',\n",
       " '$$\\n',\n",
       " '\\n',\n",
       " 'が成立しているとする．ただし，$f(\\\\cdot)$は活性化関数 (activation function)，$\\\\mathbf{U} \\\\in \\\\mathbb{R}^{n_0 \\\\times n_1}$は重み行列である．\\n',\n",
       " '$\\\\boldsymbol{\\\\epsilon} \\\\in \\\\mathbb{R}^{n_0}$ は $\\\\mathcal{N}(\\\\mathbf{0}, \\\\sigma^2 \\\\mathbf{I})$ からサンプリングされるとする．\\n',\n",
       " '\\n',\n",
       " '潜在変数 $\\\\mathbf{r}$はさらに高次 (higher-level)の潜在変数 $\\\\mathbf{r}^h$により，次式で表現される．\\n',\n",
       " '\\n',\n",
       " '$$\\n',\n",
       " '\\\\mathbf{r} = \\\\mathbf{r}^{td}+\\\\boldsymbol{\\\\epsilon}^{td}=f(\\\\mathbf{U}^h \\\\mathbf{r}^h)+\\\\boldsymbol{\\\\epsilon}^{td} \\\\tag{2}\\n',\n",
       " '$$\\n',\n",
       " '\\n',\n",
       " 'ただし，Top-downの予測信号を $\\\\mathbf{r}^{td}:=f(\\\\mathbf{U}^h \\\\mathbf{r}^h)$とした．また，$\\\\mathbf{r}^{td} \\\\in \\\\mathbb{R}^{n_1}$, $\\\\mathbf{r}^{h} \\\\in \\\\mathbb{R}^{n_2}$, $\\\\mathbf{U}^h \\\\in \\\\mathbb{R}^{n_1 \\\\times n_2}$ である．\\n',\n",
       " '$\\\\boldsymbol{\\\\epsilon}^{td} \\\\in \\\\mathbb{R}^{n_1}$は$\\\\mathcal{N}(\\\\mathbf{0}$, $\\\\sigma_{td}^2 \\\\mathbf{I}$) からサンプリングされるとする．\\n',\n",
       " '\\n',\n",
       " '話は飛ぶが，Predictive codingのネットワークの特徴は\\n',\n",
       " '\\\\begin{itemize}\\n',\n",
       " '\\\\item 階層的な構造\\n',\n",
       " '\\\\item 高次による低次の予測 (Feedback or Top-down信号)\\n',\n",
       " '\\\\item 低次から高次への誤差信号の伝搬 (Feedforward or Bottom-up 信号)\\n',\n",
       " '\\\\end{itemize}\\n',\n",
       " '\\n',\n",
       " 'である．ここまでは高次表現による低次表現の予測，というFeedback信号について説明してきたが，この部分はSparse codingでも同じである．それではPredictive codingのもう一つの要となる，低次から高次への予測誤差の伝搬というFeedforward信号はどのように導かれるのだろうか．結論から言えば，これは\\\\textbf{復元誤差 (reconstruction error)の最小化を行う再帰的ネットワーク (recurrent network)を考慮することで自然に導かれる}．\\n']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55787e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tex2)):\n",
    "    if tex2[i][-1:] != \"\\n\":\n",
    "        tex2[i] += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "043ff239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\section{予測符号化}\\n',\n",
       " '\\\\subsection{観測世界の階層的予測}\\n',\n",
       " '\\\\textbf{階層的予測符号化(hierarchical predictive coding; HPC)} は\\\\cite{Rao1999-zv}により導入された．構築するネットワークは入力層を含め，3層のネットワークとする．LGNへの入力として画像 $\\\\mathbf{x} \\\\in \\\\mathbb{R}^{n_0}$を考える．画像 $\\\\mathbf{x}$ の観測世界における隠れ変数，すなわち\\\\textbf{潜在変数} (latent variable)を$\\\\mathbf{r} \\\\in \\\\mathbb{R}^{n_1}$とし，ニューロン群によって発火率で表現されているとする (真の変数と $\\\\mathbf{r}$は異なるので文字を分けるべきだが簡単のためにこう表す)．このとき，\\n',\n",
       " '\\n',\n",
       " '$$\\n',\n",
       " '\\\\mathbf{x} = f(\\\\mathbf{U}\\\\mathbf{r}) + \\\\boldsymbol{\\\\epsilon} \\\\tag{1}\\n',\n",
       " '$$\\n',\n",
       " '\\n',\n",
       " 'が成立しているとする．ただし，$f(\\\\cdot)$は活性化関数 (activation function)，$\\\\mathbf{U} \\\\in \\\\mathbb{R}^{n_0 \\\\times n_1}$は重み行列である．\\n',\n",
       " '$\\\\boldsymbol{\\\\epsilon} \\\\in \\\\mathbb{R}^{n_0}$ は $\\\\mathcal{N}(\\\\mathbf{0}, \\\\sigma^2 \\\\mathbf{I})$ からサンプリングされるとする．\\n',\n",
       " '\\n',\n",
       " '潜在変数 $\\\\mathbf{r}$はさらに高次 (higher-level)の潜在変数 $\\\\mathbf{r}^h$により，次式で表現される．\\n',\n",
       " '\\n',\n",
       " '$$\\n',\n",
       " '\\\\mathbf{r} = \\\\mathbf{r}^{td}+\\\\boldsymbol{\\\\epsilon}^{td}=f(\\\\mathbf{U}^h \\\\mathbf{r}^h)+\\\\boldsymbol{\\\\epsilon}^{td} \\\\tag{2}\\n',\n",
       " '$$\\n',\n",
       " '\\n',\n",
       " 'ただし，Top-downの予測信号を $\\\\mathbf{r}^{td}:=f(\\\\mathbf{U}^h \\\\mathbf{r}^h)$とした．また，$\\\\mathbf{r}^{td} \\\\in \\\\mathbb{R}^{n_1}$, $\\\\mathbf{r}^{h} \\\\in \\\\mathbb{R}^{n_2}$, $\\\\mathbf{U}^h \\\\in \\\\mathbb{R}^{n_1 \\\\times n_2}$ である．\\n',\n",
       " '$\\\\boldsymbol{\\\\epsilon}^{td} \\\\in \\\\mathbb{R}^{n_1}$は$\\\\mathcal{N}(\\\\mathbf{0}$, $\\\\sigma_{td}^2 \\\\mathbf{I}$) からサンプリングされるとする．\\n',\n",
       " '\\n',\n",
       " '話は飛ぶが，Predictive codingのネットワークの特徴は\\n',\n",
       " '\\\\begin{itemize}\\n',\n",
       " '\\\\item 階層的な構造\\n',\n",
       " '\\\\item 高次による低次の予測 (Feedback or Top-down信号)\\n',\n",
       " '\\\\item 低次から高次への誤差信号の伝搬 (Feedforward or Bottom-up 信号)\\n',\n",
       " '\\\\end{itemize}\\n',\n",
       " '\\n',\n",
       " 'である．ここまでは高次表現による低次表現の予測，というFeedback信号について説明してきたが，この部分はSparse codingでも同じである．それではPredictive codingのもう一つの要となる，低次から高次への予測誤差の伝搬というFeedforward信号はどのように導かれるのだろうか．結論から言えば，これは\\\\textbf{復元誤差 (reconstruction error)の最小化を行う再帰的ネットワーク (recurrent network)を考慮することで自然に導かれる}．\\n']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4fc705a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", 'w', encoding='UTF-8') as f:\n",
    "    f.writelines(tex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79059186",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_itemized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5d995e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\section{予測符号化}',\n",
       " '\\\\subsection{観測世界の階層的予測}',\n",
       " '\\\\textbf{階層的予測符号化(hierarchical predictive coding; HPC)} は\\\\cite{Rao1999-zv}により導入された．構築するネットワークは入力層を含め，3層のネットワークとする．LGNへの入力として画像 $\\\\mathbf{x} \\\\in \\\\mathbb{R}^{n_0}$を考える．画像 $\\\\mathbf{x}$ の観測世界における隠れ変数，すなわち\\\\textbf{潜在変数} (latent variable)を$\\\\mathbf{r} \\\\in \\\\mathbb{R}^{n_1}$とし，ニューロン群によって発火率で表現されているとする (真の変数と $\\\\mathbf{r}$は異なるので文字を分けるべきだが簡単のためにこう表す)．このとき，',\n",
       " '',\n",
       " '$$',\n",
       " '\\\\mathbf{x} = f(\\\\mathbf{U}\\\\mathbf{r}) + \\\\boldsymbol{\\\\epsilon} \\\\tag{1}',\n",
       " '$$',\n",
       " '',\n",
       " 'が成立しているとする．ただし，$f(\\\\cdot)$は活性化関数 (activation function)，$\\\\mathbf{U} \\\\in \\\\mathbb{R}^{n_0 \\\\times n_1}$は重み行列である．',\n",
       " '$\\\\boldsymbol{\\\\epsilon} \\\\in \\\\mathbb{R}^{n_0}$ は $\\\\mathcal{N}(\\\\mathbf{0}, \\\\sigma^2 \\\\mathbf{I})$ からサンプリングされるとする．',\n",
       " '',\n",
       " '潜在変数 $\\\\mathbf{r}$はさらに高次 (higher-level)の潜在変数 $\\\\mathbf{r}^h$により，次式で表現される．',\n",
       " '',\n",
       " '$$',\n",
       " '\\\\mathbf{r} = \\\\mathbf{r}^{td}+\\\\boldsymbol{\\\\epsilon}^{td}=f(\\\\mathbf{U}^h \\\\mathbf{r}^h)+\\\\boldsymbol{\\\\epsilon}^{td} \\\\tag{2}',\n",
       " '$$',\n",
       " '',\n",
       " 'ただし，Top-downの予測信号を $\\\\mathbf{r}^{td}:=f(\\\\mathbf{U}^h \\\\mathbf{r}^h)$とした．また，$\\\\mathbf{r}^{td} \\\\in \\\\mathbb{R}^{n_1}$, $\\\\mathbf{r}^{h} \\\\in \\\\mathbb{R}^{n_2}$, $\\\\mathbf{U}^h \\\\in \\\\mathbb{R}^{n_1 \\\\times n_2}$ である．',\n",
       " '$\\\\boldsymbol{\\\\epsilon}^{td} \\\\in \\\\mathbb{R}^{n_1}$は$\\\\mathcal{N}(\\\\mathbf{0}$, $\\\\sigma_{td}^2 \\\\mathbf{I}$) からサンプリングされるとする．',\n",
       " '',\n",
       " '話は飛ぶが，Predictive codingのネットワークの特徴は',\n",
       " '\\\\item 階層的な構造\\n\\\\begin{itemize}',\n",
       " '\\\\item 高次による低次の予測 (Feedback or Top-down信号)\\n\\\\begin{itemize}',\n",
       " '\\\\item 低次から高次への誤差信号の伝搬 (Feedforward or Bottom-up 信号)\\n\\\\begin{itemize}',\n",
       " '',\n",
       " 'である．ここまでは高次表現による低次表現の予測，というFeedback信号について説明してきたが，この部分はSparse codingでも同じである．それではPredictive codingのもう一つの要となる，低次から高次への予測誤差の伝搬というFeedforward信号はどのように導かれるのだろうか．結論から言えば，これは\\\\textbf{復元誤差 (reconstruction error)の最小化を行う再帰的ネットワーク (recurrent network)を考慮することで自然に導かれる}．']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "87d4edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "md = f.read()\n",
    "# convert\n",
    "text = markdown2latex(md)\n",
    "#text = all_remove(text, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7b50c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r\"\"\"##Hamiltonianネットワークの方が安定して事後分布を推定することができている．ToDo: 以下の記述\n",
    "\n",
    "- ここでは重みを設定したが， {cite:p}`Echeveste2020-sh`ではRNNにBPTTで重みを学習させている．\n",
    "- 動的な入力に対するサンプリング {cite:p}`Berkes2011-xj`．burn-inがなくなり効率良くサンプリングできる．\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9f68478b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##Hamiltonianネットワークの方が安定して事後分布を推定することができている．ToDo: 以下の記述\\n\\n- ここでは重みを設定したが， {cite:p}`Echeveste2020-sh`ではRNNにBPTTで重みを学習させている．\\n- 動的な入力に対するサンプリング {cite:p}`Berkes2011-xj`．burn-inがなくなり効率良くサンプリングできる．\\n'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2a236c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = markdown2latex(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8fd533f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##Hamiltonianネットワークの方が安定して事後分布を推定することができている．ToDo: 以下の記述\\n\\\\begin{itemize}\\n\\\\item ここでは重みを設定したが， \\\\cite{Echeveste2020-sh}ではRNNにBPTTで重みを学習させている．\\n\\\\item 動的な入力に対するサンプリング \\\\cite{Berkes2011-xj}．burn-inがなくなり効率良くサンプリングできる．\\n\\\\end{itemize}'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latex_itemized(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b8d78325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 14, 16, 18], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e444df8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "311eac64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "99f164ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e43ee23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\section{記号の表記}\\n本書では次のような記号表記を用いる．\\n\\\\begin{itemize}\\n\\\\item 実数全体を$\\\\mathbb{R}$, 複素数全体は$\\\\mathbb{C}$と表記する．\\n\\\\item スカラーは小文字・斜体で $x$ のように表記する．\\n\\\\item ベクトルは小文字・立体・太字で $\\\\mathbf{x}$ のように表記し，列ベクトル (縦ベクトル) として扱う．\\n\\\\item 行列は大文字・立体・太字で $\\\\mathbf{X}$ のように表記する．\\n\\\\item $n\\\\times 1$の実ベクトルの集合を $\\\\mathbb{R}^n$, $n\\\\times m$ の実行列の集合を $\\\\mathbb{R}^{n\\\\times m}$と表記する．\\n\\\\item 行列 $\\\\mathbf{X}$ の置換は $\\\\mathbf{X}^\\\\top$と表記する．ベクトルの要素を表す場合は $\\\\mathbf{x} = (x_1, x_2,\\\\cdots, x_n)^\\\\top$のように表記する．\\n\\\\item 単位行列を $\\\\mathbf{I}$ と表記する．\\n\\\\item ゼロベクトルは $\\\\mathbf{0}$ , 要素が全て1のベクトルは $\\\\mathbf{1}$ と表記する．  \\n\\\\item $e$を自然対数の底とし，指数関数を $e^x=\\\\exp(x)$と表記する．また，自然対数を $\\\\ln(x)$と表記する．\\n\\\\item 定義を$:=$を用いて行う．例えば，$f(x):=2x$は$f(x)$という関数を$2x$として定義するという意味である．\\n\\\\item 平均 $\\\\mu$, 標準偏差 $\\\\sigma$ の正規分布を $\\\\mathcal{N}(\\\\mu, \\\\sigma^2)$ と表記する．\\n\\\\end{itemize}\\n\\\\subsection{変数の命名規則}\\n\\\\begin{itemize}\\n\\\\item \\\\jl{tp1, tm1} : time plus one (t+1), time minus one (t-1)\\n\\\\end{itemize}'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cec95de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9dc801fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_idx += [False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc7b2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "splited_text.insert(2, \"\\\\begin{itemize}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3434221d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\section{記号の表記}',\n",
       " '本書では次のような記号表記を用いる．',\n",
       " '\\\\begin{itemize}',\n",
       " '\\x08egin{itemize}',\n",
       " '\\\\item 実数全体を$\\\\mathbb{R}$, 複素数全体は$\\\\mathbb{C}$と表記する．',\n",
       " '\\\\item スカラーは小文字・斜体で $x$ のように表記する．',\n",
       " '\\\\item ベクトルは小文字・立体・太字で $\\\\mathbf{x}$ のように表記し，列ベクトル (縦ベクトル) として扱う．',\n",
       " '\\\\item 行列は大文字・立体・太字で $\\\\mathbf{X}$ のように表記する．',\n",
       " '\\\\item $n\\\\times 1$の実ベクトルの集合を $\\\\mathbb{R}^n$, $n\\\\times m$ の実行列の集合を $\\\\mathbb{R}^{n\\\\times m}$と表記する．',\n",
       " '\\\\item 行列 $\\\\mathbf{X}$ の置換は $\\\\mathbf{X}^\\\\top$と表記する．ベクトルの要素を表す場合は $\\\\mathbf{x} = (x_1, x_2,\\\\cdots, x_n)^\\\\top$のように表記する．',\n",
       " '\\\\item 単位行列を $\\\\mathbf{I}$ と表記する．',\n",
       " '\\\\item ゼロベクトルは $\\\\mathbf{0}$ , 要素が全て1のベクトルは $\\\\mathbf{1}$ と表記する．  ',\n",
       " '\\\\item $e$を自然対数の底とし，指数関数を $e^x=\\\\exp(x)$と表記する．また，自然対数を $\\\\ln(x)$と表記する．',\n",
       " '\\\\item 定義を$:=$を用いて行う．例えば，$f(x):=2x$は$f(x)$という関数を$2x$として定義するという意味である．',\n",
       " '\\\\item 平均 $\\\\mu$, 標準偏差 $\\\\sigma$ の正規分布を $\\\\mathcal{N}(\\\\mu, \\\\sigma^2)$ と表記する．',\n",
       " '\\\\subsection{変数の命名規則}',\n",
       " '\\\\item \\\\jl{tp1, tm1} : time plus one (t+1), time minus one (t-1)']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splited_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e0201cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i, line in enumerate(splited_text):\n",
    "    if line:\n",
    "        print(line[0] == \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abf941ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e8c891d6a34dce88f9f1ef2988f233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preface\n",
      "introduction/intro\n",
      "introduction/computational-neuroscience\n",
      "introduction/notation\n",
      "introduction/usage-julia-lang\n",
      "['2']\n",
      "['10']\n",
      "['right! (generic function with 1 method)']\n",
      "['foo (generic function with 1 method)']\n",
      "introduction/linear-algebra\n",
      "['3-element Vector{Int64}:\\n', ' 1\\n', ' 2\\n', ' 3']\n",
      "['Any[]']\n",
      "['3×3 Matrix{Float64}:\\n', ' 0.926253  0.353171   0.343478\\n', ' 0.62924   0.0944723  0.917437\\n', ' 0.680284  0.170864   0.654275']\n",
      "['3×3 Matrix{Float64}:\\n', ' 0.414287  0.571006  0.179344\\n', ' 0.281441  0.152742  0.479032\\n', ' 0.304272  0.276252  0.341624']\n",
      "['2×2 Matrix{Int64}:\\n', ' 1  2\\n', ' 3  4']\n",
      "['2×3 Matrix{Int64}:\\n', ' 4  5  6\\n', ' 7  8  9']\n",
      "['2×5 Matrix{Int64}:\\n', ' 1  2  4  5  6\\n', ' 3  4  7  8  9']\n",
      "['2×5 Matrix{Int64}:\\n', ' 1  2  4  5  6\\n', ' 3  4  7  8  9']\n",
      "['2-element Vector{Matrix{Int64}}:\\n', ' [1 2; 3 4]\\n', ' [4 5 6; 7 8 9]']\n",
      "['5×2 Matrix{Int64}:\\n', ' 1  2\\n', ' 3  4\\n', ' 4  7\\n', ' 5  8\\n', ' 6  9']\n",
      "['5×2 Matrix{Int64}:\\n', ' 1  2\\n', ' 3  4\\n', ' 4  7\\n', ' 5  8\\n', ' 6  9']\n",
      "['5×4 Matrix{Int64}:\\n', ' 1  2  1  2\\n', ' 3  4  3  4\\n', ' 4  7  4  7\\n', ' 5  8  5  8\\n', ' 6  9  6  9']\n",
      "['3-element Vector{Float64}:\\n', ' 0.9225597515419179\\n', ' 0.658120481093438\\n', ' 0.41401801671066496']\n",
      "['1×3 Matrix{Float64}:\\n', ' 0.92256  0.65812  0.414018']\n",
      "['UniformScaling{Bool}\\n', 'true*I']\n",
      "['3×3 Diagonal{Bool, Vector{Bool}}:\\n', ' 1  ⋅  ⋅\\n', ' ⋅  1  ⋅\\n', ' ⋅  ⋅  1']\n",
      "['2-element Vector{Float64}:\\n', ' 0.5002132597166149\\n', ' 0.03509562556923285']\n",
      "['2-element Vector{Float64}:\\n', ' -0.1805788303672428\\n', '  0.8082531148175677']\n",
      "['2-element Vector{Float64}:\\n', ' -0.1805788303672428\\n', '  0.8082531148175676']\n",
      "['4×4 Matrix{Float64}:\\n', ' 1.0  5.0   9.0  13.0\\n', ' 2.0  6.0  10.0  14.0\\n', ' 3.0  7.0  11.0  15.0\\n', ' 4.0  8.0  12.0  16.0']\n",
      "['4×4 Matrix{Float64}:\\n', '  25.5193   -29.5701     5.09719  -18.3365\\n', ' -61.7388    71.768    -12.3934    44.6203\\n', '   5.53255   -6.36443    1.09258   -3.92298\\n', '   6.70725   -7.05331    1.14599   -4.0074']\n",
      "['4×4 Matrix{Float64}:\\n', ' 1.0  5.0   9.0  13.0\\n', ' 2.0  6.0  10.0  14.0\\n', ' 3.0  7.0  11.0  15.0\\n', ' 4.0  8.0  12.0  16.0']\n",
      "['2×2×2 Array{Float64, 3}:\\n', '[:, :, 1] =\\n', ' 0.915692  0.18149\\n', ' 0.132838  0.0376235\\n', '\\n', '[:, :, 2] =\\n', ' 0.807789  0.297739\\n', ' 0.569867  0.705417']\n",
      "['8-element Vector{Float64}:\\n', ' 0.9156924090979948\\n', ' 0.13283838898511735\\n', ' 0.18149003405285813\\n', ' 0.03762345094967079\\n', ' 0.8077889408656388\\n', ' 0.5698673388911334\\n', ' 0.297739498855886\\n', ' 0.7054169935372759']\n",
      "['8-element Vector{Float64}:\\n', ' 0.9156924090979948\\n', ' 0.13283838898511735\\n', ' 0.18149003405285813\\n', ' 0.03762345094967079\\n', ' 0.8077889408656388\\n', ' 0.5698673388911334\\n', ' 0.297739498855886\\n', ' 0.7054169935372759']\n",
      "['6×5 Matrix{Float64}:\\n', ' 0.286014   0.923302  0.174386   0.10705    0.744143\\n', ' 0.457232   0.234084  0.149783   0.684196   0.21295\\n', ' 0.308209   0.712286  0.903116   0.487475   6.84179e-6\\n', ' 0.0566201  0.526367  0.235321   0.0381212  0.336639\\n', ' 0.0933628  0.980388  0.0258844  0.0371784  0.849971\\n', ' 0.384149   0.628456  0.077691   0.970843   0.678124']\n",
      "introduction/differential-equation\n",
      "introduction/linear-regression\n",
      "introduction/probability-information-theory\n",
      "introduction/stochastic-process-differential-equation\n",
      "neuron-model/intro\n",
      "neuron-model/neuron-physiol\n",
      "neuron-model/hodgkin-huxley\n",
      "['update! (generic function with 1 method)']\n",
      "neuron-model/fhn\n",
      "['update! (generic function with 1 method)']\n",
      "neuron-model/lif\n",
      "['update! (generic function with 1 method)']\n",
      "neuron-model/izhikevich\n",
      "neuron-model/isi\n",
      "['rasterplot (generic function with 1 method)']\n",
      "['GammaSpike (generic function with 1 method)']\n",
      "['GammaISIplot (generic function with 2 methods)']\n",
      "neuron-model/neurite-growth-model\n",
      "synapse-model/intro\n",
      "synapse-model/synapse-physiol\n",
      "synapse-model/current-conductance-synapse\n",
      "synapse-model/expo-synapse\n",
      "synapse-model/kinetic-synapse\n",
      "['updateHH! (generic function with 1 method)']\n",
      "synapse-model/synaptic-weighted\n",
      "synapse-model/dynamical-synapses\n",
      "neuronal-computation/intro\n",
      "neuronal-computation/neuronal-arithmetic\n",
      "['update! (generic function with 1 method)']\n",
      "['GammaSpike (generic function with 1 method)']\n",
      "['FIcurve (generic function with 3 methods)']\n",
      "['HHIAFIcurve_multi (generic function with 1 method)']\n",
      "local-learning-rule/intro\n",
      "local-learning-rule/pca-hebbian-learning\n",
      "['SVD{Float64, Float64, Matrix{Float64}, Vector{Float64}}\\n', 'U factor:\\n', '2×2 Matrix{Float64}:\\n', ' -0.722509  -0.691362\\n', ' -0.691362   0.722509\\n', 'singular values:\\n', '2-element Vector{Float64}:\\n', ' 418.9073852600819\\n', ' 138.22321877667497\\n', 'Vt factor:\\n', '2×2 Matrix{Float64}:\\n', ' -0.722509  -0.691362\\n', ' -0.691362   0.722509']\n",
      "['DoG (generic function with 6 methods)']\n",
      "['relu (generic function with 1 method)']\n",
      "local-learning-rule/mds-anti-hebbian-learning\n",
      "local-learning-rule/slow-feature-analysis\n",
      "['whiten (generic function with 1 method)']\n",
      "['time_frames (generic function with 1 method)']\n",
      "['linsfa (generic function with 1 method)']\n",
      "local-learning-rule/stdp-learning\n",
      "local-learning-rule/logistic-regression-perceptron\n",
      "['1']\n",
      "['step (generic function with 1 method)']\n",
      "local-learning-rule/self-organizing-map\n",
      "['make_blobs (generic function with 1 method)']\n",
      "['Umatrix2d (generic function with 1 method)']\n",
      "['find_bmu (generic function with 1 method)']\n",
      "energy-based-model/intro\n",
      "energy-based-model/energy-based-model\n",
      "energy-based-model/hopfield-model\n",
      "['corrupted (generic function with 2 methods)']\n",
      "energy-based-model/boltzmann-machine\n",
      "['(28, 28, 60000)']\n",
      "['20']\n",
      "['4']\n",
      "['energy (generic function with 1 method)']\n",
      "energy-based-model/sparse-coding\n",
      "['soft_nonneg_thres (generic function with 1 method)']\n",
      "['updateOF! (generic function with 1 method)']\n",
      "['normalize_rows (generic function with 1 method)']\n",
      "['calculate_total_error (generic function with 1 method)']\n",
      "['run_simulation (generic function with 1 method)']\n",
      "energy-based-model/predictive-coding\n",
      "['update! (generic function with 1 method)']\n",
      "['gaussian_2d (generic function with 4 methods)']\n",
      "['run_simulation (generic function with 1 method)']\n",
      "solve-credit-assignment-problem/intro\n",
      "solve-credit-assignment-problem/backpropagation-zipser-andersen\n",
      "solve-credit-assignment-problem/linear-network-learning-dynamics\n",
      "solve-credit-assignment-problem/bptt\n",
      "['update! (generic function with 1 method)']\n",
      "solve-credit-assignment-problem/surrogate-gradient-snn\n",
      "solve-credit-assignment-problem/reservoir-computing\n",
      "motor-learning/intro\n",
      "motor-learning/minimum-jerk\n",
      "['solveEqualityConstrainedQuadProg (generic function with 1 method)']\n",
      "['6']\n",
      "motor-learning/minimum-variance\n",
      "['minimum_variance_model (generic function with 1 method)']\n",
      "motor-learning/optimal-feedback-control\n",
      "['Reaching1DModelCostParameter']\n",
      "['LQG (generic function with 1 method)']\n",
      "['gLQG (generic function with 3 methods)']\n",
      "['simulation (generic function with 1 method)']\n",
      "['simulation_all (generic function with 1 method)']\n",
      "motor-learning/infinite-horizon-ofc\n",
      "['SaccadeModelParameter']\n",
      "['infinite_horizon_ofc (generic function with 3 methods)']\n",
      "['simulation (generic function with 4 methods)']\n",
      "['1.0']\n",
      "['target_jump_simulation (generic function with 6 methods)']\n",
      "motor-learning/biological-ofc\n",
      "['Reaching1DModelCostParameter']\n",
      "['LQG (generic function with 1 method)']\n",
      "['simulation (generic function with 1 method)']\n",
      "['simulation_all (generic function with 1 method)']\n",
      "motor-learning/rat-trajectory\n",
      "reinforcement-learning/intro\n",
      "reinforcement-learning/td-learning\n",
      "bayesian-brain/intro\n",
      "bayesian-brain/neural-uncertainty-representation\n",
      "bayesian-brain/bayesian-linear-regression\n",
      "bayesian-brain/mcmc\n",
      "['MixtureModel{IsoNormal}(K = 2)\\n', 'components[1] (prior = 0.5000): IsoNormal(\\n', 'dim: 2\\n', 'μ: [0.0, 0.0]\\n', 'Σ: [1.0 0.0; 0.0 1.0]\\n', ')\\n', '\\n', 'components[2] (prior = 0.5000): IsoNormal(\\n', 'dim: 2\\n', 'μ: [3.0, 3.0]\\n', 'Σ: [1.0 0.0; 0.0 1.0]\\n', ')\\n', '\\n']\n",
      "['grad (generic function with 1 method)']\n",
      "['([1.0 0.5551053858555393 … 2.5978715364957816 2.5978715364957816; 0.5 -0.6019397439354577 … 2.2316937524389115 2.2316937524389115], 1191)']\n",
      "['(2, 2000)']\n",
      "['10000']\n",
      "['(0.001, 5.0)']\n",
      "['ulp (generic function with 1 method)']\n",
      "['4-element Vector{Float64}:\\n', '  11.502179436027728\\n', ' -29.136001309910146\\n', ' -28.331966074802352\\n', '   1.0557387545081587']\n",
      "bayesian-brain/neural-sampling\n",
      "['membrane_potential (generic function with 4 methods)']\n",
      "['∇ᵤlogP (generic function with 1 method)']\n",
      "bayesian-brain/probabilistic-population-coding\n",
      "bayesian-brain/quantile-expectile-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['normal_equation (generic function with 1 method)']\n",
      "['kde (generic function with 3 methods)']\n",
      "appendix/intro\n",
      "appendix/grid-cells-decoding\n",
      "['MAT.MAT_v5.Matlabv5File(IOStream(<file ../_static/datasets/grid_cells_data/10704-07070407_T2C3.mat>), false, #undef)']\n",
      "['nearest_pos (generic function with 1 method)']\n",
      "appendix/graph-theory-network-model\n",
      "[\"PyObject <module 'networkx' from 'C:\\\\\\\\Users\\\\\\\\yamta\\\\\\\\miniconda3\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\networkx\\\\\\\\__init__.py'>\"]\n",
      "appendix/useful-links\n",
      "appendix/usage-jupyter-book\n"
     ]
    }
   ],
   "source": [
    "            main_list.append(r\"\\input{./text/\"+filename+\".tex}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
