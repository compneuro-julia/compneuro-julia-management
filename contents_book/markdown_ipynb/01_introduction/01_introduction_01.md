# 第1章：はじめに
## 本書の目的と構成
### 神経科学における計算論
本書では神経科学における数理モデルを主として取り扱う．初めに神経科学におけるモデルの役割について触れておこう．まず，神経科学の目標は端的に言えば「脳神経系を理解する」ことにある．神経科学に限らず，種々の学問分野においては実験と理論の2本柱で，対象とする現象や物質の理解が進められる．ここで実験は調査等も踏まえ実データを取る行為とする．理論の役割は複数あり，実験結果の抽象化および統合，仮説の提供，現象の予測等である \citep{Blohm2020-vc}．

「脳神経系を理解する」ということに関して，その定義は研究者により様々である．ここでは脳の計算処理に関する理論的理解を進めるための1つの方法として Marrの3レベル (Marr's Three Levels) を紹介する \citep{Marr1982-wk}．Marrの3レベルは視覚系における計算処理の理解を主としていたが，他でも適用可能である．3レベルとは(1)計算理論 (computational theory), (2) 表現・アルゴリズム (representation and algorithm), (3)実装 (implementation) であり，それぞれの段階での議論や理解を行う．(1)では脳の目的関数とそれを用いた最適化問題の設定を行う．(2)では(1)を実現するための表現およびアルゴリズムを解明する．(3)では(1,2)を神経回路・ハードウェア上で実装する方法を解明することを目標とし，平易には「脳」を作って理解すると言い換えることもできる\footnote{ここでの「作る」は計算機等でシミュレーションするという意味であり，脳オルガノイド (brain organoid) を作成するなどの意味ではない}．本書ではこの(3)を重視し，読者が自らの手で理論を検証し，数値計算による結果を再現できることを目標とした．また，本書は数式をプログラミングのコードに変換する具体例集としての役割も持っている．

モデルの中でも，本書では機械学習に関連する内容が多数登場する．これは神経科学と機械学習は互いに影響を及ぼし合ってきたためである \citep{Hassabis2017-zm}. 
神経科学から機械学習への応用は例えば，ニューラルネットワーク，記憶モデル，注意モデルなどがある．逆に機械学習から神経科学への応用は強化学習，運動制御，ベイズ脳仮説などが挙げられる．

筆者の立場としては，神経科学は機械学習の発展のためにあるわけではないので，後者の流れ，すなわち機械学習から神経科学への応用を重視して本書を執筆した次第である．

### 本書の構成
第1章では，Julia言語の使用法と用いる数学について簡単に説明する．第2章から第5章までは発火率モデルおよびニューラルネットワークについての説明を行う．第2章では，まず神経細胞の簡単な生理学について説明する．発火率モデルを説明したのち，局所学習則によって訓練されるネットワークの説明を行う．第3章では，同じく局所学習則ではあるが，ネットワーク全体のエネルギーを下げることを目的としたエネルギーベースモデルと呼ばれる枠組みのネットワークについて説明をする．第4章では，誤差逆伝播法に基づいたニューラルネットワークを説明し，貢献度分配問題の生理学的な解決策について説明をする．第5章では，さらに再起型ニューラルネットワークを説明し，経時的貢献度分配問題について説明を行う．

第6・7章ではスパイキングニューラルネットワークとその学習について取り扱う．第6章ではネットワークレベルの話から再び神経細胞とシナプスに回帰する．次に，シナプスのダイナミクスについて説明を補いながらモデルを構築する．第7章ではネットワークの構築と学習について，第2章から第5章までを踏まえて説明する．

第8章から12章は上記以外の内容について各論的に説明を行う．第8章のリザバーコンピューティングの章では，リザバーコンピューティングと呼ばれる枠組みのネットワークおよびその学習則について，発火率・スパイキングモデルの双方をまとめて紹介する．第9章ではベイズ推論の章では，神経回路網により，如何にして確率計算を行うかを説明する．第10章では運動学習では，最適制御問題の解決策について説明する．第11章の強化学習では，強化学習の基本的事項の説明と，大脳基底核との関連性について説明する．第12章は補足的な話題であり，ネットワーク・形態学・グリアについて説明を行う．
