\documentclass[titlepage]{ltjsbook}
\usepackage[
  paperheight=232truemm, paperwidth=182truemm,
  top=20truemm, bottom=15truemm, inner=15truemm, outer=15truemm
  ]{geometry}

%\documentclass[tombow, paper={182truemm, 232truemm}, titlepage]{ltjsbook}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{mathrsfs}

\usepackage{textgreek}
\usepackage[luatex]{graphicx} 
\usepackage[svgnames]{xcolor}
\usepackage{sty/julia-syntax-highlighting} % 
\usepackage{sty/indexing} % 

\usepackage[export]{sty/adjustbox} % added

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyfoot{}
\fancyhead[RO, LE]{\thepage}
\fancyhead[LO]{\nouppercase{\leftmark}}
\fancyhead[RE]{\nouppercase{\rightmark}}

%\renewcommand{\chaptermark}[1]{\markboth{#1}{} }
\renewcommand{\chaptermark}[1]{\markboth{第\ \thechapter\ 章. ~#1}{}}
% \renewcommand{\chaptermark}[1]{\markboth{\MakeUppercase{第\chaptername \thechapter 章.\ #1}}{}}
% \renewcommand{\headrulewidth}{0pt}

\usepackage{hyperref}

% https://ja.overleaf.com/learn/latex/Bibliography_management_with_bibtex
\usepackage[
    backend=biber,
    bibencoding=utf8,
    style=authoryear-comp, 
    url=false,
    isbn=true,
    doi=true,
    natbib=true, 
    alldates=year,
    maxcitenames=2,
    uniquelist=false, 
    sorting=ynt,
    sortcites=true,
    giveninits=true,
    terseinits=false,
    refsegment=chapter
]{biblatex}

\addbibresource{../references/07_bayesian-brain.bib}

\DeclareNameAlias{author}{last-first}
\AtEveryBibitem{\clearlist{language}}
\renewbibmacro{in:}{}

\newcommand{\jl}{\lstinline[language=julia]}

\title{\Huge \textbf{Juliaで作って学ぶ計算論的神経科学}}
\author{\huge 山本 拓都}
\date{\huge \today} 

\begin{document}
%\maketitle
\setcounter{tocdepth}{2}
\tableofcontents
\clearpage
\chapter{生成モデルとベイズ脳仮説}
\section{推論的知覚と生成モデル}
\subsection{逆問題と推論的知覚}
これまでの章では，知覚 (perception) のモデル，すなわち外界からの入力に対して，どのようにして神経回路網が意味のある出力を生成するのか，という問題を主に扱ってきた．ここで改めて知覚の基本的な定義を確認しておこう．知覚とは，外界からの刺激を感覚受容器によって受容し，それに意味を与える過程である．この「刺激に意味を与える」という個所を，より体系的に理解するために，「順問題」と「逆問題」という概念を導入しよう．

一般に，ある原因から結果を予測する問題は順問題 (forward problem) と呼ばれる．逆に，観測された結果からその原因を推定する問題は逆問題 (inverse problem) と呼ばれる．視覚を例にとって，順問題と逆問題について考えてみよう．たとえば，三次元の物体が光を反射し，それが二次元の網膜上にどのような像を結ぶか，という問いは順問題に分類される．これに対して，網膜上に投影された二次元像から，元の物体の三次元的な構造や大きさ，位置などを推定する課題が逆問題である\footnote{他にも逆問題は数多く存在する．逆問題は様々な分野に現れるが，ここでは医学や神経科学に関連した例として，外部から脳の構造や機能を推定する問題を取り上げる．たとえば，医用画像解析では，コンピュータ断層撮影 (computed tomography; CT) ，磁気共鳴画像法 (magnetic resonance imaging; MRI) ，陽電子放射断層撮影 (positron emission tomography; PET) などにおいて，観測データから画像を再構成する必要がある．この再構成処理には，CTやPETでは逆ラドン変換，MRIでは逆フーリエ変換が用いられる．また，神経活動を非侵襲的に計測する手法として，脳波 (electroencephalography; EEG) や脳磁図 (magnetoencephalography; MEG) がある．これらにおける電流源推定 (source localization) も典型的な逆問題である．EEGやMEGにおける順問題は，脳内の神経電流源の位置・方向・強度から，頭皮上の電極 (EEG) や磁場センサ (MEG) によって観測される電位や磁場分布を予測することである．一方，逆問題は，実際に観測された電位や磁場データから，神経電流源の空間的位置と活動を推定することである．この逆問題は不良設定 (ill-posed) であるため，安定的に解くには，MRIから得られた頭部の構造データに基づいて構築された順モデル (forward model) が必要となる．}．光学の分野では，それぞれの問題は順光学 (forward optics) ，逆光学 (inverse optics) と呼ばれている．逆問題は多くの場合，不良設定問題 (ill-posed problem) となる．すなわち，解が存在しない，解が一意に定まらない，あるいはわずかな誤差に対して解が大きく変化するといった性質をもつ\footnote{これに対して，良設定問題 (well-posed problem) とは，解が存在し，一意であり，かつ入力の変動に対して連続的に変化する (安定性をもつ) ような問題を指す．良設定問題では，入力データに小さなノイズや誤差が含まれていても，求められる解は大きく変わることなく，安定に計算することができる．}．例えば，先ほどの例であれば同じ2次元像を示す3次元物体は複数 (あるいは無数に) 存在する．そのため，逆問題を解くには，事前知識や仮定 (制約条件，正則化) の導入などが必要となる．

こうした逆問題を踏まえ，知覚とは単なる入力情報の受動的な処理ではなく，感覚入力という結果から外界に存在する潜在的な原因を推定する逆推論 (abductive reasoning) の過程とみなす考えがある \citep{helmholtz1867, mumford1992computational, kawato1993forward, friston2003learning}\footnote{Helmholtz は，知覚を単なる感覚の受容ではなく，感覚入力に意味を与え，対象として構成する過程であると捉えた．この過程には，観念の連合 (\textit{Vorstellungsverbindungen}) が関与している．観念の連合とは，過去の経験によって形成された (必ずしも言語化を伴わない) 観念や知識が，現在の感覚入力と結び付けられる過程を指す．通常，推論とは意識的に行われるものと考えられているが，Helmholtz はこのような観念の連合を，意識されることなく行われる推論として捉え，無意識的推論 (\textit{unbewusster Schluss}, unconscious inference)  と表現した．なお，この脚注ではドイツ語を斜体で表記した．}．この枠組みを推論的知覚 (perception as inference) と呼ぶ．次節では，この推論的知覚を支える数理モデルである，生成モデル (generative model) について詳しく見ていこう．

\subsection{生成モデル}
生成モデルとは，学習データに内在する特徴や構造を学習し，それに基づいて新たなデータを生成するモデルである．ここで，学習対象となる観測データ (例えば感覚入力) を $\mathbf{x} \in \mathbb{R}^d$ とし，それらが従う真の確率密度関数を $p_{\mathrm{data}}(\cdot)$ と表す．この密度関数 $p_{\mathrm{data}}(\cdot)$ は，実世界においてデータがどのように生成されるかを記述するものであり，$\mathbf{x}$ における確率密度は $p_{\mathrm{data}}(\mathbf{x})$ で与えられる．このような密度関数 $p_{\mathrm{data}}(\cdot)$ が既知であれば，任意のサンプル $\mathbf{x}$ をそこから生成 (サンプリング) することができる．しかし現実には，$p_{\mathrm{data}}(\cdot)$ は明示的な形では与えられておらず，ほとんどの場合において未知である．観測データがある確率的な生成過程に従って生じたと仮定し，その過程を表現するために，パラメータ $\theta$ をもつ確率密度関数 $p_\theta(\mathbf{x})$ を導入する．ここで，$p_\theta(\mathbf{x})$ は，観測変数 $\mathbf{x}$ に対する条件付き分布 $p(\mathbf{x} \mid \theta)$ の略記である．このような分布 $p_\theta(\mathbf{x})$ を定めるモデルを，生成モデル (generative model) と呼ぶ．

生成モデルの学習における目的は，パラメータ $\theta$ を調整して，生成モデルが定める確率密度関数 $p_\theta(\mathbf{x})$ を，学習データが従う真の分布 $p_{\mathrm{data}}(\mathbf{x})$ に近づけることである．この「近づける」という操作には，両分布間の差異を定量化する指標，すなわち確率分布間の距離 (あるいは不一致度) を定義する必要がある．ここではその尺度として，Kullback–Leiblerダイバージェンス (KLダイバージェンス) を用いる：
\begin{equation}
D_{\mathrm{KL}}\left(p_{\mathrm{data}}(\mathbf{x}) \,\Vert\, p_\theta(\mathbf{x})\right)
:= \int p_{\mathrm{data}}(\mathbf{x}) \log \frac{p_{\mathrm{data}}(\mathbf{x})}{p_\theta(\mathbf{x})} \, d\mathbf{x}
\end{equation}
このKLダイバージェンスは，真の分布 $p_{\mathrm{data}}(\mathbf{x})$ を基準としたときに，モデル分布 $p_\theta(\mathbf{x})$ がどれだけ情報的に乖離しているかを測る指標である．すなわち，モデルが生成する分布が，実際のデータ分布からどの程度逸脱しているかを定量化するものである．このKLダイバージェンスを展開すると，
\begin{align}
D_{\mathrm{KL}}\left(p_{\mathrm{data}}(\mathbf{x}) \,\Vert\, p_\theta(\mathbf{x})\right)
&= \int p_{\mathrm{data}}(\mathbf{x}) \log \frac{p_{\mathrm{data}}(\mathbf{x})}{p_\theta(\mathbf{x})} \, d\mathbf{x} \\
&= \int p_{\mathrm{data}}(\mathbf{x}) \log p_{\mathrm{data}}(\mathbf{x}) \, d\mathbf{x} 
\ - \int p_{\mathrm{data}}(\mathbf{x}) \log p_\theta(\mathbf{x}) \, d\mathbf{x} \\
&= \text{const.} - \mathbb{E}_{\mathbf{x} \sim p_{\mathrm{data}}} \left[ \log p_\theta(\mathbf{x}) \right]
\end{align}
となる．ここで第1項は $\theta$ に依存しない定数であるため，パラメータ $\theta$ を最適化する際には，第2項 (対数尤度の期待値) のみを考慮すればよい．したがって，最適なパラメータ $\theta^*$ は，
\begin{equation}
\theta^* = \arg\min_\theta D_{\mathrm{KL}}\left(p_{\mathrm{data}} \,\Vert\, p_\theta\right)
= \arg\max_\theta \mathbb{E}_{\mathbf{x} \sim p_{\mathrm{data}}} \left[ \log p_\theta(\mathbf{x}) \right]
\end{equation}
として求められる．しかし実際には，真の分布 $p_{\mathrm{data}}(\mathbf{x})$ の形は不明であり，観測されるのは有限個のデータ点 $\{\mathbf{x}_i\}_{i=1}^N$ のみである．そこで，真の分布の代替として，以下のような経験分布 (empirical distribution) $\hat{p}_{\mathrm{data}}(\mathbf{x})$ を用いる：
\begin{equation}
\hat{p}_{\mathrm{data}}(\mathbf{x}) := \frac{1}{N} \sum_{i=1}^N \delta(\mathbf{x} - \mathbf{x}_i)
\end{equation}
ここで，$\delta(\cdot)$ は Dirac のデルタ関数であり，この経験分布 $\hat{p}_{\mathrm{data}}(\mathbf{x})$ は，観測された各データ点の位置にのみ確率を集中させるような離散的な点分布である．すなわち、サンプル $\{\mathbf{x}_i\}_{i=1}^N$ 以外の点では確率密度がゼロであり、各 $\mathbf{x}_i$ に等しい重み $1/N$ を割り当てている．この近似を用いることで，最適化問題は次のように書き換えられる：
\begin{equation}
\theta^* \approx \arg\max_\theta \mathbb{E}_{\mathbf{x} \sim \hat{p}_{\mathrm{data}}} \left[ \log p_\theta(\mathbf{x}) \right]
= \arg\max_\theta \sum_{i=1}^N \log p_\theta(\mathbf{x}_i)
\end{equation}
これは，観測されたデータに対する対数尤度のサンプル平均を最大化する操作に対応し，最尤推定 (maximum likelihood estimation; MLE) と呼ばれる．

この最適化問題をさらに具体的に扱うためには，確率密度関数 $p_\theta(\mathbf{x})$ の形式を明示的に定める必要がある．そこで次に，この $p_\theta(\mathbf{x})$ をどのような構造のもとに構築するかを紹介する．
\printbibliography[segment=\therefsegment,heading=subbibliography,title={参考文献}]
\addcontentsline{toc}{section}{参考文献}
\end{document}