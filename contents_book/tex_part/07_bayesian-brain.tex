\documentclass[titlepage]{ltjsbook}
\usepackage[
  paperheight=232truemm, paperwidth=182truemm,
  top=20truemm, bottom=15truemm, inner=15truemm, outer=15truemm
  ]{geometry}

%\documentclass[tombow, paper={182truemm, 232truemm}, titlepage]{ltjsbook}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{mathrsfs}

\usepackage{textgreek}
\usepackage[luatex]{graphicx} 
\usepackage[svgnames]{xcolor}
\usepackage{sty/julia-syntax-highlighting} % 
\usepackage{sty/indexing} % 

\usepackage[export]{sty/adjustbox} % added

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyfoot{}
\fancyhead[RO, LE]{\thepage}
\fancyhead[LO]{\nouppercase{\leftmark}}
\fancyhead[RE]{\nouppercase{\rightmark}}

%\renewcommand{\chaptermark}[1]{\markboth{#1}{} }
\renewcommand{\chaptermark}[1]{\markboth{第\ \thechapter\ 章. ~#1}{}}
% \renewcommand{\chaptermark}[1]{\markboth{\MakeUppercase{第\chaptername \thechapter 章.\ #1}}{}}
% \renewcommand{\headrulewidth}{0pt}

\usepackage{hyperref}

% https://ja.overleaf.com/learn/latex/Bibliography_management_with_bibtex
\usepackage[
    backend=biber,
    bibencoding=utf8,
    style=authoryear-comp, 
    url=false,
    isbn=true,
    doi=true,
    natbib=true, 
    alldates=year,
    maxcitenames=2,
    uniquelist=false, 
    sorting=ynt,
    sortcites=true,
    giveninits=true,
    terseinits=false,
    refsegment=chapter
]{biblatex}

\addbibresource{../references/07_bayesian-brain.bib}

\DeclareNameAlias{author}{last-first}
\AtEveryBibitem{\clearlist{language}}
\renewbibmacro{in:}{}

\newcommand{\jl}{\lstinline[language=julia]}

\title{\Huge \textbf{Juliaで作って学ぶ計算論的神経科学}}
\author{\huge 山本 拓都}
\date{\huge \today} 

\begin{document}
%\maketitle
\setcounter{tocdepth}{2}
\tableofcontents
\clearpage
\chapter{生成モデルとベイズ脳仮説}
%\section{推論的知覚と生成モデル}
%\subsection{逆問題と推論的知覚}
これまでの章では，知覚 (perception) のモデル，すなわち外界からの入力に対して，どのようにして神経回路網が意味のある出力を生成するのか，という問題を主に扱ってきた．ここで改めて知覚の基本的な定義を確認しておこう．知覚とは，外界からの刺激を感覚受容器によって受容し，それに意味を与える過程である．この「刺激に意味を与える」という個所を，より体系的に理解するために，「順問題」と「逆問題」という概念を導入しよう．

一般に，ある原因から結果を予測する問題は順問題 (forward problem) と呼ばれる．逆に，観測された結果からその原因を推定する問題は逆問題 (inverse problem) と呼ばれる．視覚を例にとって，順問題と逆問題について考えてみよう．たとえば，三次元の物体が光を反射し，それが二次元の網膜上にどのような像を結ぶか，という問いは順問題に分類される．これに対して，網膜上に投影された二次元像から，元の物体の三次元的な構造や大きさ，位置などを推定する課題が逆問題である\footnote{他にも逆問題は数多く存在する．逆問題は様々な分野に現れるが，ここでは医学や神経科学に関連した例として，外部から脳の構造や機能を推定する問題を取り上げる．たとえば，医用画像解析では，コンピュータ断層撮影 (computed tomography; CT) ，磁気共鳴画像法 (magnetic resonance imaging; MRI) ，陽電子放射断層撮影 (positron emission tomography; PET) などにおいて，観測データから画像を再構成する必要がある．この再構成処理には，CTやPETでは逆ラドン変換，MRIでは逆フーリエ変換が用いられる．また，神経活動を非侵襲的に計測する手法として，脳波 (electroencephalography; EEG) や脳磁図 (magnetoencephalography; MEG) がある．これらにおける電流源推定 (source localization) も典型的な逆問題である．EEGやMEGにおける順問題は，脳内の神経電流源の位置・方向・強度から，頭皮上の電極 (EEG) や磁場センサ (MEG) によって観測される電位や磁場分布を予測することである．一方，逆問題は，実際に観測された電位や磁場データから，神経電流源の空間的位置と活動を推定することである．この逆問題は不良設定 (ill-posed) であるため，安定的に解くには，MRIから得られた頭部の構造データに基づいて構築された順モデル (forward model) が必要となる．}．光学の分野では，それぞれの問題は順光学 (forward optics) ，逆光学 (inverse optics) と呼ばれている．逆問題は多くの場合，不良設定問題 (ill-posed problem) となる．すなわち，解が存在しない，解が一意に定まらない，あるいはわずかな誤差に対して解が大きく変化するといった性質をもつ\footnote{これに対して，良設定問題 (well-posed problem) とは，解が存在し，一意であり，かつ入力の変動に対して連続的に変化する (安定性をもつ) ような問題を指す．良設定問題では，入力データに小さなノイズや誤差が含まれていても，求められる解は大きく変わることなく，安定に計算することができる．}．例えば，先ほどの例であれば同じ2次元像を示す3次元物体は複数 (あるいは無数に) 存在する．そのため，逆問題を解くには，事前知識や仮定 (制約条件，正則化) の導入などが必要となる．

こうした逆問題を踏まえ，知覚とは単なる入力情報の受動的な処理ではなく，感覚入力という結果から外界に存在する潜在的な原因を推定する逆推論 (abductive reasoning) の過程とみなす考えがある \citep{helmholtz1867, mumford1992computational, kawato1993forward, friston2003learning}\footnote{Helmholtz は，知覚を単なる感覚の受容ではなく，感覚入力に意味を与え，対象として構成する過程であると捉えた．この過程には，観念の連合 (\textit{Vorstellungsverbindungen}) が関与している．観念の連合とは，過去の経験によって形成された (必ずしも言語化を伴わない) 観念や知識が，現在の感覚入力と結び付けられる過程を指す．通常，推論とは意識的に行われるものと考えられているが，Helmholtz はこのような観念の連合を，意識されることなく行われる推論として捉え，無意識的推論 (\textit{unbewusster Schluss}, unconscious inference)  と表現した．なお，この脚注ではドイツ語を斜体で表記した．}．この枠組みを推論的知覚 (perception as inference) と呼ぶ．推論的知覚は, 外界の潜在的な原因から感覚入力が生成される過程を記述する確率的生成モデル (probabilistic generative model) に基づいて説明される. 確率的生成モデルについて説明する前に，前提となるベイズ推論について次節で説明する．
%本章で触れる内容についてまとめ直す．

\section{ベイズ推論の基礎}
\subsection{ベイズの定理と確率的生成モデル}
ベイズ推論 (Bayesian inference) は, 未知のパラメータや潜在変数 (latent variable) を含むモデル内部の未知量を確率変数として扱い, 観測データによってその確率分布を更新する方法である. 頻度主義 (frequentism) では, これらの未知量を固定された値とみなし, その値をデータから推定する. 一方, ベイズ的立場では, パラメータ $\theta$ や潜在変数 $z$ を不確実性をもつ確率変数とみなし, その不確実性を確率分布として表す. なお, 潜在変数を含むモデルの扱いは次節で述べ, 本節ではパラメータ $\theta$ のみに焦点を当てる. 

ここで, $i$ 番目の観測データ（確率変数）を $X_i \in \mathbb{R}^d$ とし, その観測値（実現値）を $x_i$ と書く．確率変数の集合を $\mathcal{D} = \{X_i\}_{i=1}^N$ とする. 観測前のパラメータ分布を事前分布 (prior) $p(\theta)$, 観測後の分布を事後分布 (posterior) $p(\theta \mid \mathcal{D})$ と呼び, この更新を規定する関係式がベイズの定理 (Bayes' theorem) である. ベイズの定理は
\begin{equation}
p(\theta \mid \mathcal{D}) = \frac{p(\mathcal{D} \mid \theta)\, p(\theta)}{p(\mathcal{D})}
\end{equation}
で与えられる. ここで
\begin{equation}
p(\mathcal{D}) = \int p(\mathcal{D} \mid \theta)\, p(\theta)\, \mathrm{d}\theta
\end{equation}
は周辺尤度 (marginal likelihood) または証拠 (evidence) と呼ばれる. ベイズの定理は
\begin{equation}
p(\theta, \mathcal{D}) = p(\mathcal{D} \mid \theta)\, p(\theta) = p(\theta \mid \mathcal{D})\, p(\mathcal{D})
\end{equation}
が成り立つことから導かれる．ここで $p(\theta, \mathcal{D})$ は $\theta$ と $\mathcal{D}$ の同時確率分布 (joint probability distribution) である．
観測が独立同分布 (i.i.d.) に従うと仮定すれば, 
\begin{equation}
p(\mathcal{D} \mid \theta) = \prod_{i=1}^N p(x_i \mid \theta)
\end{equation}
となる. この条件付き確率 $p(\mathcal{D} \mid \theta)$ (あるいは $p(x \mid \theta)$)は, データ $\mathcal{D}$ (あるいは $x$) か, パラメータ $\theta$ のどちらを変数とみなすかによって2通りの解釈がある．
\paragraph{確率モデルとしての解釈}
$\theta$ を固定し, $x$ を確率変数として扱うとき, $p(x \mid \theta)$ は「$\theta$ が与えられたときに, どのようなデータ $x$ がどの確率で得られるか」を表す. 
\paragraph{尤度としての解釈} 観測データ集合 $\mathcal{D} = \{x_i\}$ を固定し, $\theta$ を変数として扱うとき, 
\begin{equation}
L(\theta; \mathcal{D}) := p(\mathcal{D} \mid \theta) = \prod_{i=1}^N p(x_i \mid \theta)
\end{equation}
を尤度関数と呼ぶ. 尤度は, 仮定した $\theta$ の下でデータが得られる「尤もらしさ」を定量化する指標であり, 値が大きいほどデータをよく説明すると解釈できる. なお, 尤度関数は $\theta$ に関する確率分布ではないため, $\theta$ について積分しても必ずしも1にはならない. 

事後分布 $p(\theta \mid \mathcal{D})$ は、観測データを得た後のパラメータ $\theta$ の確率分布であり、ベイズ推論はこの分布を更新する過程とみなせる。十分に更新された事後分布が得られれば、新たなデータの予測も可能となる。予測においては事後分布全体を平均化した事後予測分布 (posterior predictive distribution) を用いる. 予測対象のデータを $\tilde{x}$ とすると, 
\begin{align}
p^*(\tilde{x}) := p(\tilde{x} \mid \mathcal{D})
&= \int p(\tilde{x} \mid \theta, \mathcal{D}) \, p(\theta \mid \mathcal{D}) \, \mathrm{d}\theta \\
&= \int p(\tilde{x} \mid \theta) \, p(\theta \mid \mathcal{D}) \, \mathrm{d}\theta
\quad (\because \tilde{x} \perp\!\!\!\perp \mathcal{D} \mid \theta)
\end{align}
となる. ここで最後の等式は, 「$\theta$ が与えられた条件下で $\tilde{x}$ と $\mathcal{D}$ が独立」という条件付き独立性を用いたものである. ベイズ推論において, この事後予測分布 $p^*(\tilde{x})$ が真の生成分布の推定結果となる. 

%生成モデルとまとめて整理する．

\subsection{ベイズ線形回帰}

\subsection{最尤推定とMAP推定}

\section{生成モデル}
生成モデルとは，学習データに内在する特徴や構造を学習し，それに基づいて新たなデータを生成するモデルである．ここで，学習対象となる観測データ (例えば感覚入力) を $\mathbf{x} \in \mathbb{R}^d$ とし，それらが従う真の確率密度関数を $p_{\mathrm{data}}(\cdot)$ と表す．この密度関数 $p_{\mathrm{data}}(\cdot)$ は，実世界においてデータがどのように生成されるかを記述するものであり，$\mathbf{x}$ における確率密度は $p_{\mathrm{data}}(\mathbf{x})$ で与えられる．このような密度関数 $p_{\mathrm{data}}(\cdot)$ が既知であれば，任意のサンプル $\mathbf{x}$ をそこから生成 (サンプリング) することができる．しかし現実には，$p_{\mathrm{data}}(\cdot)$ は明示的な形では与えられておらず，ほとんどの場合において未知である．観測データがある確率的な生成過程に従って生じたと仮定し，その過程を表現するために，パラメータ $\theta$ をもつ確率密度関数 $p_\theta(\mathbf{x})$ を導入する．ここで，$p_\theta(\mathbf{x})$ は，観測変数 $\mathbf{x}$ に対する条件付き分布 $p(\mathbf{x} \mid \theta)$ の略記である．このような分布 $p_\theta(\mathbf{x})$ を定めるモデルを，生成モデル (generative model) と呼ぶ．

生成モデルの学習における目的は，パラメータ $\theta$ を調整して，生成モデルが定める確率密度関数 $p_\theta(\mathbf{x})$ を，学習データが従う真の分布 $p_{\mathrm{data}}(\mathbf{x})$ に近づけることである．この「近づける」という操作には，両分布間の差異を定量化する指標，すなわち確率分布間の距離 (あるいは不一致度) を定義する必要がある．ここではその尺度として，Kullback–Leiblerダイバージェンス (KLダイバージェンス) を用いる：
\begin{equation}
D_{\mathrm{KL}}\left(p_{\mathrm{data}}(\mathbf{x}) \,\Vert\, p_\theta(\mathbf{x})\right)
:= \int p_{\mathrm{data}}(\mathbf{x}) \log \frac{p_{\mathrm{data}}(\mathbf{x})}{p_\theta(\mathbf{x})} \, d\mathbf{x}
\end{equation}
このKLダイバージェンスは，真の分布 $p_{\mathrm{data}}(\mathbf{x})$ を基準としたときに，モデル分布 $p_\theta(\mathbf{x})$ がどれだけ情報的に乖離しているかを測る指標である．すなわち，モデルが生成する分布が，実際のデータ分布からどの程度逸脱しているかを定量化するものである．このKLダイバージェンスを展開すると，
\begin{align}
D_{\mathrm{KL}}\left(p_{\mathrm{data}}(\mathbf{x}) \,\Vert\, p_\theta(\mathbf{x})\right)
&= \int p_{\mathrm{data}}(\mathbf{x}) \log \frac{p_{\mathrm{data}}(\mathbf{x})}{p_\theta(\mathbf{x})} \, d\mathbf{x} \\
&= \int p_{\mathrm{data}}(\mathbf{x}) \log p_{\mathrm{data}}(\mathbf{x}) \, d\mathbf{x} 
\ - \int p_{\mathrm{data}}(\mathbf{x}) \log p_\theta(\mathbf{x}) \, d\mathbf{x} \\
&= \text{const.} - \mathbb{E}_{\mathbf{x} \sim p_{\mathrm{data}}} \left[ \log p_\theta(\mathbf{x}) \right]
\end{align}
となる．ここで第1項は $\theta$ に依存しない定数であるため，パラメータ $\theta$ を最適化する際には，第2項 (対数尤度の期待値) のみを考慮すればよい．したがって，最適なパラメータ $\theta^*$ は，
\begin{equation}
\theta^* = \arg\min_\theta D_{\mathrm{KL}}\left(p_{\mathrm{data}} \,\Vert\, p_\theta\right)
= \arg\max_\theta \mathbb{E}_{\mathbf{x} \sim p_{\mathrm{data}}} \left[ \log p_\theta(\mathbf{x}) \right]
\end{equation}
として求められる．しかし実際には，真の分布 $p_{\mathrm{data}}(\mathbf{x})$ の形は不明であり，観測されるのは有限個のデータ点 $\{\mathbf{x}_i\}_{i=1}^N$ のみである．そこで，真の分布の代替として，以下のような経験分布 (empirical distribution) $\hat{p}_{\mathrm{data}}(\mathbf{x})$ を用いる：
\begin{equation}
\hat{p}_{\mathrm{data}}(\mathbf{x}) := \frac{1}{N} \sum_{i=1}^N \delta(\mathbf{x} - \mathbf{x}_i)
\end{equation}
ここで，$\delta(\cdot)$ は Dirac のデルタ関数であり，この経験分布 $\hat{p}_{\mathrm{data}}(\mathbf{x})$ は，観測された各データ点の位置にのみ確率を集中させるような離散的な点分布である．すなわち, サンプル $\{\mathbf{x}_i\}_{i=1}^N$ 以外の点では確率密度がゼロであり, 各 $\mathbf{x}_i$ に等しい重み $1/N$ を割り当てている．この近似を用いることで，最適化問題は次のように書き換えられる：
\begin{equation}
\theta^* \approx \arg\max_\theta \mathbb{E}_{\mathbf{x} \sim \hat{p}_{\mathrm{data}}} \left[ \log p_\theta(\mathbf{x}) \right]
= \arg\max_\theta \sum_{i=1}^N \log p_\theta(\mathbf{x}_i)
\end{equation}
これは，観測されたデータに対する対数周辺尤度のサンプル平均を最大化する操作に対応し，最尤推定と一致する．

この最適化問題をさらに具体的に扱うためには，確率密度関数 $p_\theta(\mathbf{x})$ の形式を明示的に定める必要がある．そこで次に，この $p_\theta(\mathbf{x})$ をどのような構造のもとに構築するかを紹介する．

\printbibliography[segment=\therefsegment,heading=subbibliography,title={参考文献}]
\addcontentsline{toc}{section}{参考文献}
\end{document}