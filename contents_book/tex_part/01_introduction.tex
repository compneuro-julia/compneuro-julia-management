\documentclass[titlepage]{ltjsbook}
\usepackage[
 paperheight=232truemm, paperwidth=182truemm,
 top=20truemm, bottom=15truemm, inner=15truemm, outer=15truemm
 ]{geometry}

%\documentclass[tombow, paper={182truemm, 232truemm}, titlepage]{ltjsbook}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{mathrsfs}

\usepackage{textgreek}
\usepackage[luatex]{graphicx} 
\usepackage[svgnames]{xcolor}
\usepackage{sty/julia-syntax-highlighting} % 
\usepackage{sty/indexing} % 
\usepackage{multirow}
\usepackage{tablefootnote}
\usepackage[export]{sty/adjustbox} % added
\usepackage{adjustbox}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyfoot{}
\fancyhead[RO, LE]{\thepage}
\fancyhead[LO]{\nouppercase{\leftmark}}
\fancyhead[RE]{\nouppercase{\rightmark}}

%\renewcommand{\chaptermark}[1]{\markboth{#1}{} }
\renewcommand{\chaptermark}[1]{\markboth{第\ \thechapter\ 章. ~#1}{}}
% \renewcommand{\chaptermark}[1]{\markboth{\MakeUppercase{第\chaptername \thechapter 章.\ #1}}{}}
% \renewcommand{\headrulewidth}{0pt}

\usepackage{hyperref}

% https://ja.overleaf.com/learn/latex/Bibliography_management_with_bibtex
\usepackage[
  backend=biber,
  bibencoding=utf8,
  style=apa,%authoryear-comp, 
  url=false,
  isbn=true,
  doi=true,
  natbib=true, 
  alldates=year,
  maxcitenames=2,
  uniquelist=false, 
  sorting=nty,
  sortcites=true,
  giveninits=true,
  terseinits=false,
  refsegment=chapter
]{biblatex}

\addbibresource{../references/01_introduction.bib}

\DeclareNameAlias{author}{last-first}
\AtEveryBibitem{\clearlist{language}}
\renewbibmacro{in:}{}

% https://stackoverflow.com/questions/69682457/extended-links-in-citations
% \makeatletter
% \renewbibmacro*{cite}{%
%  \printtext[bibhyperref]{\iffieldundef{shorthand}
%   {\ifthenelse{\ifnameundef{labelname}\OR\iffieldundef{labelyear}}
%    {\usebibmacro{cite:label}%
%     \setunit{\printdelim{nonameyeardelim}}}
%    {\printnames{labelname}%
%     \setunit{\printdelim{nameyeardelim}}}%
%   \usebibmacro{cite:labeldate+extradate}}
%   {\usebibmacro{cite:shorthand}}}}
% \makeatother

\newcommand{\jl}{\lstinline[language=julia]}

\usepackage{tikz}
\newcommand{\narrowtriangle}[2]{%
 \tikz[baseline=-0.5ex]{\filldraw[black] (0,0) -- (#1,0) -- ({#1/2},-#2) -- cycle;}%
}

\title{\Huge \textbf{Juliaで作って学ぶ計算論的神経科学}}
\author{\huge 山本 拓都}
\date{\huge \today} 

\begin{document}
%\maketitle
\setcounter{tocdepth}{2}
\tableofcontents
\clearpage
\chapter{はじめに}
\section{本書の目的と構成}
\subsection{神経科学におけるモデルの意義}
本書では, 神経科学における数理モデルの構築とJulia言語での実装を中心的な主題とし, その背景にある計算論的理論と実践的手法を扱う. 初めに, 神経科学におけるモデルの意義について整理しておこう. 

神経科学の重要な目標の一つは, ミクロからマクロまで, また基礎から臨床にわたる幅広い研究領域とスケールの観点から, 脳神経系の構造 (structure) と機能 (function) について科学的説明を与えることである. 

この目標に向けて, 自然科学に共通するように, 神経科学もまた実験と理論という二つの柱に支えられて発展してきた. 実験は観察や計測を通じて実データを得る行為であり, 理論はデータを整理・統合し, 予測や検証すべき問い (仮説) を導き出すための枠組みとなる. 

モデルは？

特にモデルは, 次のような多面的な役割を担っている \citep{Blohm2020-vc,levenstein2023role,van2024critical}：
 (1) 仮説の駆動と明示化, (2) 複雑な知見の整理と統合, (3) 観察結果の再現や予測, 仮説の提供 (4) 仮想実験の実行, (5) 科学的コミュニケーションの明確化, (6) 臨床や技術への応用可能性の提供である. このように, モデルは単なる計算装置ではなく, 科学的思考そのものの外化であり, 神経科学の進展に不可欠な知的道具である. 

次に「科学的説明」ということに関してどのような観点があるのかを述べる．神経科学における科学的説明の分類として有名なのがMarrの3つのレベル (Marr's Three Levels of analysis) \citep{Marr1982-wk} である．

解析や理論のレベル．

Marrは～

次に，DayanとAbbottは～

これらの科学的説明に関してまとめたものが次の表である．

分析レベル

とはいえ，あるモデルは何に属するか，というのは明確に区別づけられないため，本書では「これは何モデル」と明示的に記載はしない．

本書では，これらの3つのモデルの

\setlength{\tabcolsep}{2pt}
\begin{table}[]
\centering
\begin{adjustbox}{width=\linewidth}
\begin{tabular}{c|c|cccc}
\hline
スケール & \begin{tabular}{c}主要な\\説明の観点 \end{tabular} & \citep{Marr1982-wk} & \citep{pylyshyn1984computation} & \citep{anderson1990adaptive} & \citep{dayan2005theoretical} \\ \hline
マクロ & \begin{tabular}{c}なぜ\\(Why) \end{tabular} & \begin{tabular}{c}計算理論\\(Computational theory) \end{tabular} & \begin{tabular}{c}意味論的\\(Semantic) \end{tabular} & \begin{tabular}{c}合理的\\(Rational) \end{tabular} & \begin{tabular}{c}解釈的\\(Interpretive)\end{tabular}\\\cline{2-6}
\multirow{4}{*}{\narrowtriangle{0.5}{1.8}} & & 表現と & アルゴリズム & アルゴリズム & \\
& どのように & アルゴリズム & (Algorithm) & (Algorithm) & 記述的\\\cline{4-5}
& (How) & \multirow{2}{*}{
 \begin{tabular}{c}\(
\biggl(
\begin{array}{c}
\!\!\text{Representation}\!\!\\[-4pt]
\!\!\text{and algorithm}\!\!
\end{array}
\biggr)
\)\end{tabular}
} & 機能的構造 & 実装 & (Descriptive)\\
& & & (Functional architecture) & (Implementation)\\\cline{2-6}
ミクロ & \begin{tabular}{c}何が/何を\\(What) \end{tabular} & 
\begin{tabular}{c}ハードウェア実装\\
\(
\biggl(
\begin{array}{c}
\!\!\text{Hardware}\!\!\\[-4pt]
\!\!\text{implementation}\!\!
\end{array}
\biggr)
\)\end{tabular}& \begin{tabular}{c}生物学的\\(Biological) \end{tabular} & \begin{tabular}{c}生物学的\\(Biological)\end{tabular} & \begin{tabular}{c}機構的\\(Mechanistic) \end{tabular}\\ \hline
\end{tabular}
\end{adjustbox}
\caption{説明・解析のレベル}
\label{tb:levels_of_analysis}
\end{table}

\setlength{\tabcolsep}{5pt}
\begin{table}[]
\centering
%\begin{adjustbox}{width=\linewidth}
\begin{tabular}{c|c|c}
\hline
説明レベル & 内容 & 例\\\hline
計算理論& &\\
表現とアルゴリズム& &\\
ハードウェア実装& &\\\hline
\end{tabular}
%\end{adjustbox}
\caption{\citep{Marr1982-wk} における説明・解析のレベル}
\end{table}

\setlength{\tabcolsep}{5pt}
\begin{table}[]
\centering
%\begin{adjustbox}{width=\linewidth}
\begin{tabular}{c|c|c}
\hline
説明レベル & 内容 & 例\\\hline
解釈的& &\\
記述的& &\\
機構的& &\\\hline
\end{tabular}
%\end{adjustbox}
\caption{\citep{dayan2005theoretical} における説明・解析のレベル}
\end{table}

合理的解析 (Rational analysis) では，システムが環境下で特定の目的を「合理的」に達成すると仮定した際に，その行動を支配する制約条件や，計算が達成すべき規範を特定する．

% 分割統治の一種である．

% The Adaptive Character of Thought

%https://books.google.com.bz/books?id=T5JBLb1cNUgC&printsec=copyright#v=onepage&q&f=false

%https://www.eneuro.org/content/7/1/ENEURO.0352-19.2019
%https://www.jneurosci.org/content/43/7/1074
%https://journals.sagepub.com/doi/full/10.1177/17456916231191744


本書では, こうした理解の枠組みを与えるために, Marrの3つのレベル (Marr's Three Levels) \citep{Marr1982-wk} およびDayanとAbbottによる3レベルを紹介する．

対応するモデル

科学的説明の分類は複数あるが，

解釈 (interpretive), 説明 (descriptive) and mechanistic approaches


Interpretive model (解釈的モデル, why) ：行動や最適性の観点から機構を説明する (例：ベイズ推論, 強化学習) 

Descriptive model (記述的モデル, how) ：データの構造や統計的特徴をそのまま記述する (例：PSTH, tuning curves) 

Mechanistic model (機構的モデル, what) ：要素間の因果的な関係を定式化する (例：LIFモデル, STDP則) 

抽象的な意味的構成から，生体現象に即した具体的なモデル


%https://pubmed.ncbi.nlm.nih.gov/38252109/
%https://www.sciencedirect.com/science/article/pii/S0959438819300728?via%3Dihub

表を参考に，統合した階層を書く．

%https://physoc.onlinelibrary.wiley.com/doi/full/10.1113/JP279549

%https://physoc.onlinelibrary.wiley.com/doi/full/10.1113/JP279550?saml_referrer
%

%Dayan, P., & Abbott, L. F. (2005). Theoretical neuroscience. MIT Press.

Dayanらの序文

Theoretical analysis and computational modeling are important tools for characterizing what nervous systems do, determining how they function, and understanding why they operate in particular ways. Neuroscience encompasses approaches ranging from molecular and cellular studies to human psychophysics and psychology. Theoretical neuroscience encourages crosstalk among these subdisciplines by constructing compact representations of what has been learned, building bridges between different levels of description, and identifying unifying concepts and principles. In this book, we present the basic methods used for these purposes and discuss examples in which theoretical approaches have yielded insight into nervous system function. The questions what, how, and why are addressed by descriptive, mechanistic, and interpretive models, each of which we discuss in the following chapters. 

Descriptive models summarize large amounts of experimental data compactly yet accurately, thereby characterizing what neurons and neural circuits do. These models may be based loosely on biophysical, anatomical, and physiological findings, but their primary purpose is to describe phenomena, not to explain them. 

Mechanistic models, on the other hand, address the question of how nervous systems operate on the basis of known anatomy, physiology, and circuitry. Such models often form a bridge between descriptive models couched at different levels. 

Interpretive models use computational and information-theoretic principles to explore the behavioral and cognitive significance of various aspects of nervous system function, addressing the question of why nervous systems operate as they do.

情報処理タスクを実行するあらゆる機械を理解するために必要な3つのレベル


. これは, 脳における情報処理過程を以下の三段階で整理する視点である：

計算理論 (computational theory) ：対象とする現象において, 何をどのように計算するのか, 入力と出力の対応関係を定義する. 

表現とアルゴリズム (representation and algorithm) ：計算理論で定められた変換を, どのような内部表現と手続きにより実現するかを明示する. 

実装 (implementation) ：それらの手続きを, 神経回路やハードウェアといった物理基盤上でどのように具現化するかを示す. 

本書の立場は, これら三つのレベルを分断されたものではなく, 相互に往還可能な理解のスケールと見なすことにある. とりわけ第(3)の実装レベルに重きを置き, モデルを読者自身の手で計算機上に構築・実行し, 理論的仮説を数値的に再現・検証する力を養うことを目標とする. その意味で本書は, 数式をコードに変換するための「実践的な翻訳辞典」としても機能する. 

また, 本書で取り上げるモデルの多くは機械学習と関係している. これは神経科学と機械学習が長年にわたり相互作用してきた歴史を反映している. 神経科学から機械学習への影響には, ニューラルネットワークの構造や記憶・注意といった機能的モデルがあり, 逆に機械学習の発展が神経科学にもたらしたものとして, 強化学習に基づく意思決定理論や, ベイズ的知覚理論 (いわゆる「ベイズ脳仮説」) などが挙げられる \citep{Hassabis2017-zm}. 

筆者の立場は, 神経科学は機械学習の素材や工学的応用のためにあるのではなく, 脳そのものの理解という自律した目的を持つ学問であるというものである. そのため本書では, 「機械学習から神経科学への応用」という観点, すなわちアルゴリズム的知見を手がかりに神経過程を理解するという方向性を重視する. この視点はBlohmらが述べるように, 現象に即して問いを明確化し, モデルの仮定と評価基準を明示的に定めるという「設計としての建設的モデル化 (modeling as design) 」の理念にも通じる. 

実験とは
理論とは
実験と理論はどのように相互作用するか．機械学習との関連性．
モデルとは
説明の3分類とは
数理モデルを扱う上でのプログラミングの重要性

\subsection{本書の構成と読み方}
本書は, 計算論的神経科学および神経モデルの理解を深めるために, Julia言語を用いて数理モデルを実装しながら学習を進める形式を採用している. 第1章では, Julia言語の基本的な使用法に加え, 本書全体で用いる数学的記法について解説する. あわせて, 神経科学における「学習」と「予測」という枠組みのもと, 本書全体の立場を概説する. 

第2・3章では, 発火率モデルを用いた神経回路網の構成とその学習則について段階的に説明する. 第2章では, 神経細胞の基本的な生理学を導入し, 発火率モデルを用いた神経活動の定式化と, Hebb則やOja則などの局所学習則に基づく単純なネットワークの構築について扱う. 第3章では, 誤差逆伝播法 (Backpropagation) に基づく現代的なニューラルネットワークを扱い, そこで発生する貢献度分配問題 (credit assignment problem) を取り上げる. さらに再帰型ニューラルネットワーク (RNN) を導入し, 時間方向での貢献度分配 (経時的貢献度分配) の問題とその学習方法を解説する. 

第4章と第5章では, スパイキングニューラルネットワーク (SNN) を取り上げる. 第4章では, これまでのネットワークレベルの議論から個々の神経細胞とシナプスの動態に立ち戻り, スパイク発生とシナプス伝達の生物物理学的モデルを取り扱う. 第5章では, SNNにおけるネットワーク構築と学習について, 発火率モデルで扱った学習則や誤差伝播法との接続も含めて解説する. 

第6章以降は, 応用的・発展的トピックを各論的に扱う. 第6章では, リザバーコンピューティングという枠組みに基づき, 複雑な動的表現を活用する発火率モデルおよびスパイキングモデルについて紹介する. 第7章ではネットワーク全体のエネルギーを最小化する観点に基づくエネルギーベースモデル (例えばHopfieldネットワークやボルツマンマシン) について解説する. 神経回路網がベイズ推論を実現する可能性について, 確率的計算の関係から考察する. 第8章では, 運動学習における最適制御問題に対して, 脳がどのような計算を行っているかをモデルベースで探る. 第9章では, 強化学習の基本的枠組みと, 大脳基底核との関係について説明する. 

本書は数式を交えた理論の説明ののち，コードの説明を行うという流れに基づいて執筆を行った．この通り読むことも想定しているが，初学者にはどちらかというと，コードおよび実行した後の図を先に見て，「この章を読むことでどんな結果が得られるのか」というのを先に確認したのちに数式を確認するという流れもお勧めしたい．これは，作業の目標を理解するという意味で重要なことであるからだ．難しいと感じたら読み飛ばしてもよいし，何も理解しなくてもコードを写経するだけでも良いだろう．

\section{Julia言語の使用法}
\subsection{Julia言語の特徴}
Julia言語は

本書を執筆するにあたり，なぜJulia言語を選択したかというのにはいくつか理由がある．

JuliaはJIT (Just-In-Time) コンパイルを用いており

JITコンパイラ

実行速度が高速であること．
ライセンスフリーであり，無料で使用できること．
線型代数演算が簡便に書けること．
Unicodeを使用できるため，疑似コードに近いコードを書けること．

他の言語の候補として，MATLAB, Pythonが挙げられた．MATLABは神経科学分野で根強く使用される言語であり，線型代数計算の記述が簡便である．なお，線型代数演算の記法に関してはJuliaはMATLABを参考に構築されたため，ほぼ同様に記述することができる．また，MATLABを使用するには有償ライセンスが必要である．ただし，互換性を持ったフリーソフトウェアであるOctaveが存在することは明記しておく．

Pythonは機械学習等の豊富なライブラリと書きやすさから広く利用されている言語である．ただし，numpyを用いないと高速な処理を書けない場合が多く，ナイーブな実装では実行速度が低下してしまう問題がある．線型代数計算も簡便に書くことができず，数式をコードに変換する際の手間が増えるという問題がある．

多重ディスパッチ (multiple dispatch) があることはJulia言語の大きな特徴である．

\subsection{Julia言語のインストール方法}
Julia (\url{https://julialang.org/}) にアクセスし，`install` 

現在は \url{https://julialang.org/install/} でJuliaupを使用することが推奨されている．
個別に\url{https://julialang.org/downloads/} から使用しているOSに応じてmanual downloadを行う．

て使用しているOSのdownloadで

juliaup (\url{https://github.com/JuliaLang/juliaup}) でバージョン管理可能である．\jl{juliaup update}

また，2025年3月以降，Google Colab (\url{https://colab.google/}) においてPythonやRに並んでJuliaを選択して使用することが可能となっている．

\subsection{使用するライブラリ}

REPL
で\jl{]} を入力することで，パッケージ管理モードに移行する．

本書で使用するJuliaライブラリは以下の通りである．

- IJulia: 開発環境
- PyPlot: 描画用ライブラリ
- LinearAlgebra: 高度な線形代数演算
- Random: 

Pythonではnumpyで完結するところをライブラリをいくつも読み込む必要がある点は欠点ではある．

描画用のライブラリには `PyPlot.jl` を使用した．`PyPlot` はPythonライブラリである \jl{matplotlib} に依存したライブラリである．Juliaで完結させたい場合は `Plot.jl` や `Makie.jl` を使用することが推奨されるが，`PyPlot` (`matplotlib`) の方が高機能であるため，

Pythonがない場合は

\begin{lstlisting}[language=julia]
julia> ENV["PYTHON"] = ""
julia> ]
pkg> build PyCall
\end{lstlisting}

Pythonを既にインストールしている場合は，

\begin{lstlisting}[language=julia]
julia> ENV["PYTHON"] = raw"C:\Users\TakutoYamamoto\AppData\Local\Programs\Python\Python312\python.exe"
julia> ]
pkg> build PyCall
\end{lstlisting}

Windowsの場合
例としてPythonの実行ファイル (python.exe) への完全なパスを


\subsection{開発環境}

インタプリタ型言語である

vscode

筆者は (Pythonユーザーでもあるため) Jupyter Labを使用している．

JuliaのみでJupyter Labを使用するには

\begin{lstlisting}[language=julia]
using IJulia
jupyterlab(detached=true)
\end{lstlisting}

とすればよい．ただし，この際にCondaを入れることになるため，別途Pythonをインストールしておく方が推奨される．

p.33

\jl{Pluto.jl} を用いることも可能である

\section{Julia言語の基本構文}

%https://docs.julialang.org/en/v1/manual/noteworthy-differences/

\subsection{命名規則}
この節では，本書で用いるJuliaの変数名や関数名等に関する基本的な取り決めをまとめる．

\subsection{変数名}
\begin{tabular}{cl} \hline
 変数名 & 説明\\\hline
  \jl{nt} & 時間ステップ数 (number of time steps)\\
  \jl{t}, \jl{tt} & 時間ステップのインデックス\\\hline
\end{tabular}

\section{基礎的数学とJuliaでの記法}
本書で使用する数学的内容を整理する．

\subsection{表記法}
本書では次のような記号表記を用いる．
\begin{itemize}
\item 実数全体を $\mathbb{R}$, 自然数全体を $\mathbb{N}$, 複素数全体を $\mathbb{C}$ と表す. 
\item スカラーは小文字・斜体 (例：$x$) , ベクトルは小文字・立体・太字 (例：$\mathbf{x}$) で表し, 列ベクトル (縦ベクトル) として扱う. 行列は大文字・立体・太字 (例：$\mathbf{X}$) で表す. 
\item 実 $n\times 1$ ベクトルの集合を $\mathbb{R}^n$, 実 $n\times m$ 行列の集合を $\mathbb{R}^{n\times m}$ と表す. 
\item 行列の $(i,j)$ 成分は $x_{ij}$ または $(\mathbf{X})_{ij}$ と表す. 
\item 行列の転置は $\mathbf{X}^\top$ と書く. ベクトルの要素は $\mathbf{x} = (x_1, x_2, \dots, x_n)^\top$ のように記す. このため，ベクトルの内積は $\mathbf{x}^\top \mathbf{y}$ で表す. 
\item 単位行列を$\mathbf{I}$と表記する．$n \times n$ 次元の単位行列は $\mathbf{I}_n$ と表記する．
\item ゼロベクトルは $\mathbf{0}$, 全要素が 1 のベクトルは $\mathbf{1}$ とする. 
\item 変数 $x$ の関数は $f(x)$ などと書く. 変数 $x$ とパラメータ $a$ を特に区別する場合は $f(x; a)$ のようにセミコロン (;) で区切る. 引数を具体的に指定せず関数のみを示す場合は $f(\cdot)$ と書く. 
\item 定義には $\coloneqq$ を用いる (例：$f(x) \coloneqq 2x$) . 右辺を定義する場合は $\eqqcolon$ を用いる. 
\item スカラー $x$ の絶対値は $\lvert x \rvert$ と表す．行列 $\mathbf{X}$ の行列式は $\lvert \mathbf{X} \rvert$ と表す．
\item ベクトル $\mathbf{x}$ のユークリッドノルムは $\lVert \mathbf{x} \rVert \coloneqq \sqrt{\sum_i x_i^2}$, 一般の $p$-ノルムは $\lVert \mathbf{x} \rVert _p\coloneqq \left(\sum_i \lvert x_i \rvert ^p\right)^{1/p}$ と表す. 行列 $\mathbf{X}$ について行列ノルム（フロベニウスノルム）は $\lVert \mathbf{X} \rVert _F\coloneqq \sqrt{\sum_{i,j} x_{ij}^2}$ と表す. 
\item ベクトル・行列の微分は分子レイアウト記法 (numerator layout notation) を用いる. 
\item 近似は $\approx$ で表す (例：$a \approx b$) . 
\item 比例関係は $\propto$ を用いる (例：$a \propto b$) . 
\item 最大化・最小化の変数を明示する場合は $\arg\max_{x \in \mathcal{X}} f(x)$, $\arg\min_{x \in \mathcal{X}} f(x)$ のように表す. 
\item 平均 $\mu$, 分散 $\sigma^2$ の1次元正規分布は $\mathcal{N}(\mu, \sigma^2)$ と表記し, 確率密度関数としては $\mathcal{N}(x \mid \mu, \sigma^2)$ と表す. 他の確率分布に関しては使用する際に定義を示す．
\item 自然対数の底は $e$ とし, 指数関数を $e^x = \exp(x)$, 自然対数を $\ln(x)$ と表す. 
\item 計算結果に影響しない定数は $\mathrm{const.}$ と表す. 
\end{itemize}

\printbibliography[segment=\therefsegment,heading=subbibliography,title={参考文献}]
\addcontentsline{toc}{section}{参考文献}
\end{document}