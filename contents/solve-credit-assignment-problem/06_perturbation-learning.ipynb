{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efd56e09-e099-471c-80d2-9c1d5ad4f31c",
   "metadata": {},
   "source": [
    "https://www.science.org/doi/10.1126/sciadv.abh0146\n",
    "\n",
    "Chaotic neural dynamics facilitate probabilistic computations through sampling\n",
    "\n",
    "Effective Learning with Node Perturbation in Multi-Layer Neural Networks (fig1は図の参考になる．)\n",
    "On the stability and scalability of node perturbation learning\n",
    "Node perturbation learning without noiseless baseline\n",
    "\n",
    "どれも効率は良くない．\n",
    "\n",
    "### node perturbation (NP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d44e54b-c2e1-4b65-adec-93205e2b0a8f",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{z}_{\\ell+1}=f_\\ell\\left(\\mathbf{W}_\\ell \\mathbf{z}_\\ell +\\mathbf{b}_\\ell\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\tilde{\\mathbf{z}}_{\\ell+1}=f_\\ell\\left(\\mathbf{W}_\\ell \\tilde{\\mathbf{z}}_\\ell +\\mathbf{b}_\\ell+\\xi_\\ell \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta \\mathcal{L}=\\mathcal{L}(\\tilde{\\mathbf{z}}_{L})-\\mathcal{L}(\\mathbf{z}_{L})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta W_\\ell =- \\delta \\mathcal{L} \\frac{\\xi_\\ell}{\\sigma^2} \\mathbf{z}_{\\ell}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aea6fd-3ed5-4c85-b965-37406814a471",
   "metadata": {},
   "source": [
    "### Weight perturbation (WP)\n",
    "https://journals.aps.org/prx/abstract/10.1103/PhysRevX.13.021006\n",
    "Weight Perturbation Learning Performs Similarly or Better than Node Perturbation on Broad Classes of Temporally Extended Tasks\n",
    "\n",
    "A. Dembo and T. Kailath, Model-Free Distributed Learning, IEEE Trans. Neural Networks 1, 58 (1990).\n",
    "\n",
    "G. Cauwenberghs, A Fast Stochastic Error-Descent Algorithm for Supervised Learning and Optimization, in Advances in Neural Information Processing Systems (Morgan Kaufmann, Burlington, 1993), Vol. 5, pp. 244–251"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbab4e3-2df7-4753-bdd1-4bd7a1aa15e1",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{z}_{\\ell+1}=f_\\ell\\left(\\mathbf{W}_\\ell \\mathbf{z}_\\ell +\\mathbf{b}_\\ell\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\tilde{\\mathbf{z}}_{\\ell+1}=f_\\ell\\left((\\mathbf{W}_\\ell+\\xi_\\ell) \\tilde{\\mathbf{z}}_\\ell +\\mathbf{b}_\\ell \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta \\mathcal{L}=\\mathcal{L}(\\tilde{\\mathbf{z}}_{L})-\\mathcal{L}(\\mathbf{z}_{L})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta W_\\ell = -\\delta \\mathcal{L} \\frac{\\xi_\\ell}{\\sigma^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209b2eb6-cc29-47a7-ac16-4ddbcf796aa1",
   "metadata": {},
   "source": [
    "この手法に順方向自動微分 (Forward Mode AD) を適応したのが，Forward Gradient法である．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1b71d5-2203-4333-853c-13a760075cfe",
   "metadata": {},
   "source": [
    "pto -\\sigma^2 \\frac{\\partial L}{\\partial w_{ij}}\\)\r\n",
    "\r\n",
    "どちらの手法も、**重みの更新の期待値が勾配に比例するため、最適化の方向としては勾配降下法と同じ働きをする**ことが示されました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad160b9-1db2-4079-88aa-6ca53fd290ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b388eb-0566-4c0b-833a-a39ab2a72f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1fde24-2b83-456e-9f3e-9ef5fd188121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ad13840-9fea-41c7-b46c-95e322211ed2",
   "metadata": {},
   "source": [
    "### Directional Gradient Descent\n",
    "\n",
    "Can Forward Gradient Match Backpropagation?\n",
    "https://proceedings.mlr.press/v202/fournier23a.html\n",
    "\n",
    "https://oumpy.github.io/blog/2022/02/directional_gradient_optimization.html\n",
    "この記事では(Silver, et al., \"Learning by Directional Gradient Descent.\" ICLR. 2021)および(Baydin, et al., \"Gradients without Backpropagation\", arXiv, 2022)の解説&実装を行います．\r\n",
    "SCALING FORWARD GRADIENT WITH LOCAL LOSSES\n",
    "\n",
    "\r\n",
    "両者とも摂動 (perturbation) と方向微分(directional gradient) を用いて勾配を近似することで，誤差逆伝播法 (backpropagation)を用いずにニューラルネットワークを訓練するという手法を提案しています．gradient-free optimizationの一種とも言えるでしょう．以後，Silverらの提案手法をDODGE(Deep Online Directional Gradient Estimate), Baydinらの提案手法をFGD (Forward gradient descent)と呼ぶことにしま\n",
    "\n",
    "$$\n",
    "\\begin{align*}\r\n",
    "&\\textbf{if}\\ \\text{DODGE:}\\\\\r\n",
    "&\\quad \\mathbf{v} \\sim \\{-1, 1\\}^p\\\\\r\n",
    "&\\textbf{else if}\\ \\text{FGD:}\\\\\r\n",
    "&\\quad \\mathbf{v} \\sim \\mathcal{N}(0, \\mathbf{I})\\\\\r\n",
    "&g(\\boldsymbol{\\theta}, \\mathbf{x}) = (\\nabla L(\\boldsymbol{\\theta}, \\mathbf{x})\\cdot \\mathbf{v})\\cdot \\mathbf{v}\\\\\r\n",
    "&\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} - \\eta \\cdot g(\\boldsymbol{\\theta}, \\mathbf{x})\r\n",
    "\\end{ali\n",
    "\n",
    "\n",
    "Note that our method is novel in avoiding the truncation error of previous weight perturbation approaches by using AD rather than small but finite perturbations, thus completely avoiding the method of divided differences and its associated numeric issues.gn*}\n",
    "$$す．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ad3d86-b79f-4830-86bd-0339214b6859",
   "metadata": {},
   "source": [
    "#  方向微分によるニューラルネットワークの勾配近似\r\n",
    "この記事では([Silver, et al., \"Learning by Directional Gradient Descent.\" ICLR. 2021](https://openreview.net/forum?id=5i7lJLuhTm))および([Baydin, et al., \"Gradients without Backpropagation\", arXiv, 2022](http://arxiv.org/abs/2202.08587))の解説&実装を行います．\r\n",
    "\r\n",
    "両者とも**摂動 (perturbation)** と**方向微分(directional gradient)** を用いて勾配を近似することで，誤差逆伝播法 (backpropagation)を用いずにニューラルネットワークを訓練するという手法を提案しています．gradient-free optimizationの一種とも言えるでしょう．以後，Silverらの提案手法を**DODGE**(Deep Online Directional Gradient Estimate), Baydinらの提案手法を**FGD** (Forward gradient descent)と呼ぶことにします．\r\n",
    "\r\n",
    "この手法の利点としては近似勾配の計算にニューラルネットワークの順伝播のみしか用いないため，パラメータを並列に更新することができる，ということが挙げられます．Baydinらは脳(神経回路網)の学習則にも触れていますが，biologicalなモデルに落とし込むとすれば次のように解釈できると思います：\r\n",
    "\r\n",
    "各シナプスにおいてランダムかつ微小なシナプス伝達強度の変化 (e.g. spine headの大きさ変化) の方向を\"記憶\"しておき，損失の方向微分の値というglobal factorを各シナプスにfeedbackした上で\"記憶\"しておいた微小なシナプス伝達強度変化に乗じて再度シナプス伝達強度を大きく変化させる． \r\n",
    "\r\n",
    "ただし，これはあくまで解釈です．この機構が実現可能かどうかの議論はこの記事ではしないことにします．\r\n",
    "\r\n",
    "## 下準備1: 摂動による学習法\r\n",
    "やや外れた話題ですが，先に**摂動 (perturbation)** による勾配を使用しない単純な学習法を紹介しておきます．ニューラルネットワークのパラメータを$\\boldsymbol{\\theta} \\in \\mathbb{R}^p$, データサンプルを$\\mathbf{x}$，損失関数を$L(\\boldsymbol{\\theta}, \\mathbf{x})$とします．また，パラメータへの摂動を$\\mathbf{v}\\in \\mathbb{R}^p$とします．ここで単純な学習法とは，「パラメータに摂動を加えて損失が下がったらそのパラメータに更新する」です．\r\n",
    "\r\n",
    "$$\r\n",
    "\\begin{align*}\r\n",
    "&\\Delta L = L(\\boldsymbol{\\theta}+\\mathbf{v}, \\mathbf{x}) - L(\\boldsymbol{\\theta}, \\mathbf{x})\\\\\r\n",
    "&\\textbf{if}\\ \\Delta L < 0\\ \\text{:}\\\\\r\n",
    "&\\quad \\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta}+\\mathbf{v}\r\n",
    "\\end{align*}\r\n",
    "$$\r\n",
    "\r\n",
    "一応学習は進みますが，効率的ではありません．誤差逆伝播法を用いない学習法の研究においてベースラインとしてよく用いられます．\r\n",
    "\r\n",
    "## 下準備2: 方向微分とJacobian-vector productの計算\r\n",
    "本記事で紹介する学習則では**方向微分(directional gradient)** というものが用いられます．関数$f$について点$\\mathbf{u}$における方向$\\mathbf{v}$の方向微分は\r\n",
    "\r\n",
    "$$\r\n",
    "\\nabla_\\mathbf{v}f(\\mathbf{u})= \\lim_{h\\to 0} \\frac{f(\\mathbf{u}+h\\mathbf{v}) - f(\\mathbf{u})}{h}\r\n",
    "$$\r\n",
    "\r\n",
    "として定義されます．また$f$が点$\\mathbf{u}$において微分可能なら\r\n",
    "\r\n",
    "$$\r\n",
    "\\nabla_\\mathbf{v}f(\\mathbf{u})=\\nabla f(\\mathbf{u})\\cdot \\mathbf{v}\r\n",
    "$$\r\n",
    "\r\n",
    "が成り立ちます．ここで右辺を**Jacobian-vector product** (JVP) と呼びます．JVPを計算する上でSilverらはForward Mode ADで計算できる[`jax.jvp`](https://jax.readthedocs.io/en/latest/_autosummary/jax.jvp.html#jax.jvp)を用いています．BaydinらはPytorch実装かつ自動微分部分は自前実装したようです．Pytorchにも[`torch.autograd.functional.jvp`](https://pytorch.org/docs/stable/generated/torch.autograd.functional.jvp.html)がありますが，\"double backwards trick\"というbackwardsを2回用いる手法を用いているので勾配が必要になります．\r\n",
    "\r\n",
    "妥協案として有限差分(finite difference)を用いてJacobian-vector productを近似計算します ($\\epsilon$は小さい値です)．\r\n",
    "\r\n",
    "$$\r\n",
    "\\nabla f(\\mathbf{u})\\cdot \\mathbf{v} \\approx \\frac{f(\\mathbf{u}+\\epsilon \\mathbf{v}) - f(\\mathbf{u})}{\\epsilon}\r\n",
    "$$\r\n",
    "\r\n",
    "なお，$f(\\mathbf{u})\\in \\mathbb{R}$の場合，$\\nabla f(\\mathbf{u})\\cdot \\mathbf{v}\\in \\mathbb{R}$となります．有限差分で近似計算ができることを簡単な関数 (cos)で確かめてみましょう．先に今回使うライブラリを全てimportしておきます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494c729-db0c-483b-b765-65066e65f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finite difference\n",
    "eps = 1e-3\n",
    "\n",
    "def grad_estimation(f, u, n, mode=\"dodge\"):\n",
    "    if mode == \"dodge\":\n",
    "        v = 2*(torch.rand(n, 2) > 0.5) - 1   \n",
    "    elif mode == \"fgd\":\n",
    "        v = torch.randn(n, 2)\n",
    "    else:\n",
    "        assert False, \"mode is dodge or fgd\"\n",
    "    estimate_grad = 0\n",
    "    for i in range(n):\n",
    "        f_v, f = func(u + eps*v), func(u)\n",
    "        jvp = (f_v - f) / eps\n",
    "        estimate_grad += jvp*v[i]\n",
    "    estimate_grad /= n\n",
    "    return estimate_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34d1b35-482f-4e40-95b8-8fb1c02543da",
   "metadata": {},
   "source": [
    "## 摂動と方向微分による勾配近似\r\n",
    "それでは本題の説明をしましょう．まず，誤差逆伝播法と確率的勾配降下法(SGD)で学習する場合，誤差逆伝播法で$\\nabla L(\\boldsymbol{\\theta}, \\mathbf{x})=\\dfrac{\\partial L(\\boldsymbol{\\theta}, \\mathbf{x})}{\\partial \\boldsymbol{\\theta}}$を計算し，SGDにより\r\n",
    "\r\n",
    "$$\r\n",
    "\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} - \\eta \\cdot \\nabla L(\\boldsymbol{\\theta}, \\mathbf{x})\r\n",
    "$$\r\n",
    "\r\n",
    "とパラメータを更新します．ただし，$\\eta$は学習率です．一方，FGDとDODGEでは以下のようにパラメータを更新します．\r\n",
    "\r\n",
    "$$\r\n",
    "\\begin{align*}\r\n",
    "&\\textbf{if}\\ \\text{DODGE:}\\\\\r\n",
    "&\\quad \\mathbf{v} \\sim \\{-1, 1\\}^p\\\\\r\n",
    "&\\textbf{else if}\\ \\text{FGD:}\\\\\r\n",
    "&\\quad \\mathbf{v} \\sim \\mathcal{N}(0, \\mathbf{I})\\\\\r\n",
    "&g(\\boldsymbol{\\theta}, \\mathbf{x}) = (\\nabla L(\\boldsymbol{\\theta}, \\mathbf{x})\\cdot \\mathbf{v})\\cdot \\mathbf{v}\\\\\r\n",
    "&\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} - \\eta \\cdot g(\\boldsymbol{\\theta}, \\mathbf{x})\r\n",
    "\\end{align*}\r\n",
    "$$\r\n",
    "\r\n",
    "2つの手法は摂動をサンプリングする分布が異なるだけと言えます．ここで$\\nabla L(\\boldsymbol{\\theta}, \\mathbf{x})\\cdot \\mathbf{v}$の計算の際に$\\nabla L(\\boldsymbol{\\theta}, \\mathbf{x})$を計算する必要がないことに注意してください．また，$g(\\boldsymbol{\\theta}, \\mathbf{x})$が$\\nabla L(\\boldsymbol{\\theta}, \\mathbf{x})$の**不偏推定量(unbiased estimator)** になるということが最も重要な点です．これについての証明はそれぞれの論文に書いてあるのでそちらを参照してください．\r\n",
    "\r\n",
    "以下では数値計算を用いてこの手法で勾配が近似できることを説明します．先ほどの続きとしてcos関数のuにおける勾配を計算します．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4993745c-918d-4437-8bba-769a32733cb5",
   "metadata": {},
   "source": [
    "### 方向微分による訓練\r\n",
    "同じ構造のモデルを2つ (`model`, `model_v`) 用意し，以下のような手順でパラメータを更新します．\r\n",
    "1. `model`で順伝播を行い，`loss`を計算する．\r\n",
    "2. 勾配の推定値を保存するDict`grad_estimate`を用意する．\r\n",
    "3. 摂動`v`を生成する．この際，`model`のパラメータのkeyを辞書形式 `model.state_dict()`で取得し同じkeyで登録．同時に`model`と同じ構造の`model_v`のパラメータを`model`のパラメータに摂動`v`を加えたもので置換する．\r\n",
    "4. `model_v`で順伝播を行い，`loss_v`を計算する．\r\n",
    "5. 方向微分を`loss_v`と`loss`を用いて有限差分で計算する．\r\n",
    "6. `grad_estimate`に勾配の推定値を加算する．\r\n",
    "7. `num_direction`の数だけ3-6を繰り返す．\r\n",
    "8. `grad_estimate`の値を`num_direction`で平均化し`torch.clamp()`でgradient clippingする (数値的に不安定なため)．\r\n",
    "9. `optimizer.zero_grad()`で`model`のパラメータの勾配をzeroにする．\r\n",
    "10. `param.grad`に推定した勾配値を代入する．\r\n",
    "11. `optimizer.step()`でパラメータを更新する．\r\n",
    "\r\n",
    "前節のシミュレーションでは`num_directions`を増やさないと推定された勾配が真の勾配に近づきませんでしたが，`num_directions=1`でも学習は進行します．もちろん増やしてもいいですが，計算量が増えます．また，学習率$lr$は0.001とbackpropの0.01よりも小さいものを用いていますが，これは`lr`を0.01にすると発散したためです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883fea7d-368f-45fd-b0ef-26bf49b25f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b05ab89-7b97-4c40-b570-5b544d4da56a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
