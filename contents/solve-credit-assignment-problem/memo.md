BPTTの駄目な点
- 順・逆伝播の重みの対称性 (weight transport problem)
- 推論と訓練の2 phase存在すること．


STDPはlocal learning ruleに
local learning ruleと分類するのはどうなのか？

BP (spiral, zipser & anderson, MNIST classify, autoencoder)
FA・DFA・KP (Fashion MNIST classification; https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2021.629892/full)
Target propagation, Predictive coding (https://www.nature.com/articles/s41593-023-01514-1#MOESM1; supplement; A THEORETICAL FRAMEWORK FOR INFERENCE AND
LEARNING IN PREDICTIVE CODING NETWORKS)
Perturbation learning (https://oumpy.github.io/blog/2022/02/directional_gradient_optimization.html)

BPTT
RTRLとeligibility trace
- Random Feedback (Murray, J. M. Local online learning in recurrent networks with random feedback. eLife 8, pii: e43299 (2019).)

合成勾配はeligibility traceに含める．
BP(λ): Online Learning via Synthetic Gradients

SpikeProp
Surrogate Gradient
#BurstProp
e-prop (A solution to the learning dilemma for recurrent networks of spiking neurons)

リザバーコンピューティング
Reservior computing (rate, spike)
Edge of chaosの話をする必要あり．
Determination of the edge of criticality in echo state networks through Fisher information maximization
Lyapunov指数

- Echo state network
- FORCE
- https://www.nature.com/articles/s41598-019-50158-4
- https://www.sciencedirect.com/science/article/pii/S0893608024010086
カオスの縁


--

Rescorla–Wagner model

競合学習はそれだけで書ける．

Softhebb
https://www.pnas.org/doi/full/10.1073/pnas.1820458116

---
