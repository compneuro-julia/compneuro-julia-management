{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55f8904",
   "metadata": {},
   "source": [
    "# ランダム神経回路網の構築\n",
    "\n",
    "この節ではこれまでに実装したSNNの要素を組み合わせ、重みがランダムなネットワーク(random network)を構成してみましょう。作成するネットワークは2層から成り、1層目には10個のPoissonスパイクニューロン、2層目には1個のLIFニューロンがあるとします。1層目のニューロンから2層目のニューロンへのシナプス結合には、二重指数関数型シナプスを用います。目標は2層目のニューロンの膜電位と入力電流、1層目のニューロンのラスタープロット(raster plot)\\footnote{ラスタープロットはスパイク列を表す図で、各ニューロンが発火したことを点で表します。}を表示することです。\\par\n",
    "それではネットワークを構築してみましょう\\footnote{コードは\\texttt{./TrainingSNN/LIF\\_random\\_network.py}です。}。まず、ニューロンとシナプスのクラスを\\texttt{import}し、各種定数、入力のポアソンスパイク\\texttt{x}、結合重み\\texttt{W}、ニューロンとシナプスのモデルの各インスタンス(\\texttt{neurons}, \\texttt{synapses})、記録用の配列を定義します。注意点として、先ほどと同様に実行ファイルは\\texttt{Models}ディレクトリの親ディレクトリ内に置くようにしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c557bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Parameters: @unpack # or using UnPack\n",
    "using PyPlot, Random\n",
    "rc(\"axes.spines\", top=false, right=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66438859",
   "metadata": {},
   "source": [
    "batchを考慮しない場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f971b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kwdef mutable struct RNN{FT}\n",
    "    num_input::Int64\n",
    "    num_output::Int64\n",
    "    h::Vector{FT} = randn(num_output)\n",
    "    W_rec::Array{FT} = randn(num_output, num_output)\n",
    "    W_in::Array{FT} = randn(num_output, num_input)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d101a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn1 = RNN{Float32}(num_input=10, num_output=5);\n",
    "rnn2 = RNN{Float32}(num_input=5, num_output=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "364b152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = randn(10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "409cad42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initialize_states! (generic function with 1 method)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function initialize_states!(variable::RNN)\n",
    "    @unpack h, W_rec, W_in = variable\n",
    "    h[:] = randn(size(h))\n",
    "    W_rec[:, :] = randn(size(W_rec))\n",
    "    W_in[:, :] = randn(size(W_in))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3210bf4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward! (generic function with 1 method)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function forward!(variable::RNN, x::Array)\n",
    "    @unpack h, W_rec, W_in = variable\n",
    "    y = W_in * x + h\n",
    "    h[:] = W_rec * h\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d256c00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float32}:\n",
       "  1.3717992\n",
       " -0.63002634\n",
       "  1.5121956\n",
       " -1.0638394\n",
       " -0.4859997"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_states!.([rnn1, rnn2]);\n",
    "rnn1.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "86d0dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [rnn1, rnn2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3f59e479",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "DimensionMismatch: matrix A has dimensions (5,10), vector B has length 3",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch: matrix A has dimensions (5,10), vector B has length 3",
      "",
      "Stacktrace:",
      " [1] generic_matvecmul!(C::Vector{Float64}, tA::Char, A::Matrix{Float32}, B::Vector{Float64}, _add::LinearAlgebra.MulAddMul{true, true, Bool, Bool})",
      "   @ LinearAlgebra C:\\Users\\yamtak\\AppData\\Local\\Programs\\Julia-1.9.2\\share\\julia\\stdlib\\v1.9\\LinearAlgebra\\src\\matmul.jl:759",
      " [2] mul!",
      "   @ C:\\Users\\yamtak\\AppData\\Local\\Programs\\Julia-1.9.2\\share\\julia\\stdlib\\v1.9\\LinearAlgebra\\src\\matmul.jl:81 [inlined]",
      " [3] mul!",
      "   @ C:\\Users\\yamtak\\AppData\\Local\\Programs\\Julia-1.9.2\\share\\julia\\stdlib\\v1.9\\LinearAlgebra\\src\\matmul.jl:276 [inlined]",
      " [4] *",
      "   @ C:\\Users\\yamtak\\AppData\\Local\\Programs\\Julia-1.9.2\\share\\julia\\stdlib\\v1.9\\LinearAlgebra\\src\\matmul.jl:52 [inlined]",
      " [5] forward!(variable::RNN{Float32}, x::Vector{Float64})",
      "   @ Main .\\In[62]:3",
      " [6] top-level scope",
      "   @ .\\In[112]:3"
     ]
    }
   ],
   "source": [
    "initialize_states!.(model);\n",
    "for layer in model\n",
    "    x = forward!(layer, x)\n",
    "end\n",
    "println(x)\n",
    "println(rnn1.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbfd682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b120329",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kwdef struct Model\n",
    "    p::Float64 = 2.0\n",
    "    n::Int64 = 4\n",
    "    f::Function = x -> x + p\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kwdef struct Linear\n",
    "    num_input::Int64\n",
    "    num_output::Int64\n",
    "    f::Function = x -> x + p\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939e935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(p=7).f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72edfe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b18681",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = Linear(num_inputs, num_hidden)\n",
    "lif1 = Leaky(beta=beta)\n",
    "fc2 = Linear(num_hidden, num_outputs)\n",
    "lif2 = Leaky(beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceddf055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9606c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.Neurons import CurrentBasedLIF\n",
    "from Models.Synapses import DoubleExponentialSynapse\n",
    "\n",
    "np.random.seed(seed=0)\n",
    "\n",
    "dt = 1e-4; T = 1; nt = round(T/dt) # シミュレーション時間\n",
    "num_in = 10; num_out = 1 # 入力 / 出力ニューロンの数\n",
    "\n",
    "# 入力のポアソンスパイク\n",
    "fr_in = 30 # 入力のポアソンスパイクの発火率(Hz)\n",
    "x = np.where(np.random.rand(nt, num_in) < fr_in * dt, 1, 0)\n",
    "W = 0.2*np.random.randn(num_out, num_in) # ランダムな結合重み\n",
    "\n",
    "# モデル\n",
    "neurons = CurrentBasedLIF(N=num_out, dt=dt, tref=5e-3,\n",
    "                          tc_m=1e-2, vrest=-65, vreset=-60,\n",
    "                          vthr=-40, vpeak=30)\n",
    "synapses = DoubleExponentialSynapse(N=num_out, dt=dt, td=1e-2, tr=1e-2)\n",
    "\n",
    "# 記録用配列\n",
    "current = np.zeros((num_out, nt))\n",
    "voltage = np.zeros((num_out, nt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91525126",
   "metadata": {},
   "source": [
    "次に、\\texttt{for}ループ内でネットワークの流れを書き、シミュレーションを実行してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17194f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons.initialize_states() # 状態の初期化\n",
    "for t in tqdm(range(nt)):\n",
    "    # 更新\n",
    "    I = synapses(np.dot(W, x[t]))\n",
    "    s = neurons(I)\n",
    "\n",
    "    # 記録\n",
    "    current[:, t] = I\n",
    "    voltage[:, t] = neurons.v_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7fdc5a",
   "metadata": {},
   "source": [
    "ここでは、全結合は\\texttt{np.dot(W, x[t])}で表し、\\texttt{synapses}の出力はシナプス後電流とします。第二章で述べたように\\texttt{synapses}の出力が何を意味するのか、すなわちシナプス前細胞の神経伝達物質の放出量なのか、シナプス後細胞のチャネルの開口頻度なのかは場合によって変わるので、注意するようにしましょう。今回の場合はシナプス後細胞に注目したモデルとなっています。\\par\n",
    "最後にシミュレーションの結果を描画してみましょう。描画するのは前述したように2層目のニューロンの膜電位と入力電流、1層目のニューロンのラスタープロットです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1304497",
   "metadata": {},
   "source": [
    "## ランダムネットワークのシミュレーション\n",
    "1000個のIzニューロン(興奮性800個, 抑制性200個)によるランダムネットワークのシミュレーションを行う．これは([Izhikevich, 2003](https://www.izhikevich.org/publications/spikes.htm))においてMATLABコードが示されており，それをJuliaに移植したものである．このシミュレーションではRS(regular spiking)ニューロンを興奮性細胞，FS(fast spiking)ニューロンを抑制性細胞のモデルとして用いている．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb59cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Parameters: @unpack # or using UnPack\n",
    "using PyPlot\n",
    "rc(\"axes.spines\", top=false, right=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c642534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excitatory neurons, Inhibitory neurons\n",
    "Ne, Ni = 800, 200;\n",
    "re, ri = rand(Ne,1), rand(Ni,1)\n",
    "a = [0.02ones(Ne,1); 0.02 .+ 0.08ri]\n",
    "b = [0.2ones(Ne,1); 0.25 .- 0.05ri]\n",
    "c = [-65 .+ 15re.^2; -65ones(Ni,1)]\n",
    "d = [8 .- 6re.^2; 2ones(Ni,1)]\n",
    "S = [0.5rand(Ne+Ni,Ne) -rand(Ne+Ni,Ni)] # synaptic weight\n",
    "v = -65ones(Ne+Ni,1)   # Initial values of v\n",
    "u = b .* v              # Initial values of u\n",
    "firings = []            # spike timings\n",
    "\n",
    "for t=1:1000 # simulation of 1000 ms\n",
    "    Ie = [5randn(Ne,1); 2randn(Ni,1)] # thalamic input\n",
    "    fired = findall(v[:, 1] .>= 30) # indices of spikes\n",
    "    firings = t==1 ? [t .+ 0*fired fired] : [firings; [t .+ 0*fired fired]]\n",
    "    v[fired] = c[fired]\n",
    "    u[fired] += d[fired]\n",
    "    Ie += sum(S[:,fired], dims=2)\n",
    "    v += 0.5(0.04v.^2 + 5v .+140 - u + Ie) # step 0.5 ms for numerical stability\n",
    "    v += 0.5(0.04v.^2 + 5v .+140 - u + Ie) \n",
    "    u += a .* (b .* v - u)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5cbd2d",
   "metadata": {},
   "source": [
    "膜電位の更新の際，`v`を2回に分けて更新しているが，これは数値的な安定性を高めるためである．計算量は上がるが，前述したモデルにおいても同様の処理を行う実装もある．\n",
    "\n",
    "シミュレーションの実行後，ネットワークを構成するニューロンの発火を描画する．これを**ラスタープロット** (raster plot)という．この図は横軸が時間，縦軸がニューロンの番号となっており，各ニューロンが発火したことを点で表している．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b7155",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(6, 3))\n",
    "scatter(firings[:,1], firings[:,2], c=\"k\", s=1, alpha=0.5)\n",
    "xlabel(\"Time (ms)\"); ylabel(\"# neuron\"); xlim(0, 1000); ylim(0, 1000)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b8c1e2",
   "metadata": {},
   "source": [
    "初めの400msぐらいまでは100msごとに約10Hzの$\\alpha$波が見られ，800ms付近には約40Hzの$\\gamma$波が見られる．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
