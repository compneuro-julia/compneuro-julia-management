{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flux.jlでRNN\n",
    "\n",
    "https://www.juliabloggers.com/a-basic-rnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_data (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function generate_data(num_samples)\n",
    "    train_data = [rand(1.0:10.0, rand(2:7)) for i in 1:num_samples]\n",
    "    train_labels = (v -> sum(v)).(train_data)\n",
    "\n",
    "    test_data = 2 .* train_data\n",
    "    test_labels = 2 .* train_labels\n",
    "\n",
    "    train_data, train_labels, test_data, test_labels\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rnn = Flux.RNN(1, 1, (x -> x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux: @epochs\n",
    "\n",
    "num_samples = 1000\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate our test data with the data generation function from above\n",
    "train_data, train_labels, test_data, test_labels = generate_data(num_samples)\n",
    "simple_rnn = Flux.RNN(1, 1, (x -> x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function eval_model(x)\n",
    "    out = simple_rnn.(x)[end]\n",
    "    Flux.reset!(simple_rnn)\n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "loss(x, y) = abs(sum((eval_model(x) .- y)))\n",
    "\n",
    "ps = Flux.params(simple_rnn)\n",
    "\n",
    "# use the ADAM optimizer. It's a pretty good one!\n",
    "opt = Flux.ADAM()\n",
    "\n",
    "println(\"Training loss before = \", sum(loss.(train_data, train_labels)))\n",
    "println(\"Test loss before = \", sum(loss.(test_data, test_labels)))\n",
    "\n",
    "# callback function during training\n",
    "evalcb() = @show(sum(loss.(test_data, test_labels)))\n",
    "\n",
    "@epochs num_epochs Flux.train!(loss, ps, zip(train_data, train_labels), opt, cb = Flux.throttle(evalcb, 1))\n",
    "\n",
    "# after training, evaluate the loss\n",
    "println(\"Test loss after = \", sum(loss.(test_data, test_labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
